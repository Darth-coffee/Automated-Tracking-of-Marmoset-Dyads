{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca50a5c7",
   "metadata": {},
   "source": [
    "### Tracking videos using YOLO+SORT (change the input directory path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5212d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import csv\n",
    "import glob\n",
    "import pandas as pd\n",
    "from ultralytics import YOLO\n",
    "from filterpy.kalman import KalmanFilter\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "# SORT tracker (restricted to max 2 IDs, since we only track two marmosets)\n",
    "class SORT:\n",
    "    def __init__(self):\n",
    "        self.trackers = []\n",
    "        self.used_ids = set()\n",
    "\n",
    "    # Each tracked object is represented by a KalmanBoxTracker\n",
    "    class KalmanBoxTracker:\n",
    "        def __init__(self, bbox, assigned_id):\n",
    "            # Initialize Kalman filter for a bounding box\n",
    "            self.kf = KalmanFilter(dim_x=7, dim_z=4)\n",
    "            # State transition matrix (motion model)\n",
    "            self.kf.F = np.array([\n",
    "                [1,0,0,0,1,0,0],\n",
    "                [0,1,0,0,0,1,0],\n",
    "                [0,0,1,0,0,0,1],\n",
    "                [0,0,0,1,0,0,0],\n",
    "                [0,0,0,0,1,0,0],\n",
    "                [0,0,0,0,0,1,0],\n",
    "                [0,0,0,0,0,0,1]])\n",
    "            # Measurement matrix (maps state to bbox)\n",
    "            self.kf.H = np.array([\n",
    "                [1,0,0,0,0,0,0],\n",
    "                [0,1,0,0,0,0,0],\n",
    "                [0,0,1,0,0,0,0],\n",
    "                [0,0,0,1,0,0,0]])\n",
    "            # Uncertainty settings\n",
    "            self.kf.R[2:,2:] *= 10.\n",
    "            self.kf.P[4:,4:] *= 1000.\n",
    "            self.kf.P *= 10.\n",
    "            self.kf.Q[-1,-1] *= 0.01\n",
    "            self.kf.Q[4:,4:] *= 0.01\n",
    "            # Convert bbox to center, area, aspect ratio\n",
    "            cx, cy = (bbox[0]+bbox[2])/2, (bbox[1]+bbox[3])/2\n",
    "            s = (bbox[2]-bbox[0])*(bbox[3]-bbox[1])   # area\n",
    "            r = (bbox[2]-bbox[0]) / (bbox[3]-bbox[1]+1e-6)  # aspect ratio\n",
    "            self.kf.x[:4] = np.array([cx, cy, s, r]).reshape((4,1))\n",
    "            self.id = assigned_id\n",
    "            self.time_since_update = 0\n",
    "            self.hits = 0\n",
    "            self.hit_streak = 0\n",
    "\n",
    "        def update(self, bbox):\n",
    "            # Update tracker with new detection\n",
    "            cx, cy = (bbox[0]+bbox[2])/2, (bbox[1]+bbox[3])/2\n",
    "            s = (bbox[2]-bbox[0])*(bbox[3]-bbox[1])\n",
    "            r = (bbox[2]-bbox[0]) / (bbox[3]-bbox[1]+1e-6)\n",
    "            self.kf.update(np.array([cx, cy, s, r]).reshape((4,1)))\n",
    "            self.time_since_update = 0\n",
    "            self.hits += 1\n",
    "            self.hit_streak += 1\n",
    "\n",
    "        def predict(self):\n",
    "            # Predict next position\n",
    "            self.kf.predict()\n",
    "            self.time_since_update += 1\n",
    "            if self.time_since_update > 0:\n",
    "                self.hit_streak = 0\n",
    "            return self.get_state()\n",
    "\n",
    "        def get_state(self):\n",
    "            # Convert predicted state back to bounding box [x1,y1,x2,y2]\n",
    "            cx, cy, s, r = self.kf.x[:4].reshape(-1)\n",
    "            w = np.sqrt(s*r)\n",
    "            h = s / (w + 1e-6)\n",
    "            return [cx-w/2, cy-h/2, cx+w/2, cy+h/2]\n",
    "\n",
    "    def assign_id(self):\n",
    "        # Assign unique IDs 1 or 2\n",
    "        for i in [1, 2]:\n",
    "            if i not in self.used_ids:\n",
    "                return i\n",
    "        return None\n",
    "\n",
    "    def update(self, detections):\n",
    "        # Update tracker with new detections\n",
    "        trks = []\n",
    "        to_del = []\n",
    "        # Predict positions of existing trackers\n",
    "        for t, trk in enumerate(self.trackers):\n",
    "            pos = trk.predict()\n",
    "            if np.any(np.isnan(pos)) or trk.time_since_update > 30:\n",
    "                to_del.append(t)  # remove stale trackers\n",
    "            else:\n",
    "                trks.append(pos)\n",
    "        # Delete old trackers\n",
    "        for t in reversed(to_del):\n",
    "            self.used_ids.discard(self.trackers[t].id)\n",
    "            self.trackers.pop(t)\n",
    "\n",
    "        trks = np.array(trks)\n",
    "        dets = detections[:, :4] if len(detections) > 0 else np.empty((0,4))\n",
    "        # Match detections with trackers\n",
    "        matched, unmatched_dets, unmatched_trks = self.associate_detections_to_trackers(dets, trks)\n",
    "\n",
    "        # Update matched trackers\n",
    "        for m in matched:\n",
    "            self.trackers[m[1]].update(detections[m[0], :4])\n",
    "\n",
    "        # Increment age of unmatched trackers\n",
    "        for t in unmatched_trks:\n",
    "            self.trackers[t].time_since_update += 1\n",
    "\n",
    "        # Create new trackers for unmatched detections (only up to 2 IDs)\n",
    "        for i in unmatched_dets:\n",
    "            if len(self.trackers) >= 2:\n",
    "                continue\n",
    "            new_id = self.assign_id()\n",
    "            if new_id is not None:\n",
    "                trk = SORT.KalmanBoxTracker(detections[i, :4], new_id)\n",
    "                self.trackers.append(trk)\n",
    "                self.used_ids.add(new_id)\n",
    "\n",
    "        # Prepare return values (only active trackers)\n",
    "        ret = []\n",
    "        for trk in self.trackers:\n",
    "            if trk.time_since_update < 1 and (trk.hits >= 3 or len(self.trackers) <= 2):\n",
    "                d = trk.get_state()\n",
    "                ret.append([*d, trk.id])\n",
    "        return ret\n",
    "\n",
    "    def iou(self, bb_test, bb_gt):\n",
    "        # Intersection-over-Union (IoU) for matching bboxes\n",
    "        xx1 = np.maximum(bb_test[0], bb_gt[0])\n",
    "        yy1 = np.maximum(bb_test[1], bb_gt[1])\n",
    "        xx2 = np.minimum(bb_test[2], bb_gt[2])\n",
    "        yy2 = np.minimum(bb_test[3], bb_gt[3])\n",
    "        w = np.maximum(0., xx2 - xx1)\n",
    "        h = np.maximum(0., yy2 - yy1)\n",
    "        wh = w*h\n",
    "        return wh / ((bb_test[2]-bb_test[0])*(bb_test[3]-bb_test[1]) + \n",
    "                     (bb_gt[2]-bb_gt[0])*(bb_gt[3]-bb_gt[1]) - wh + 1e-6)\n",
    "\n",
    "    def associate_detections_to_trackers(self, detections, trackers):\n",
    "        # Match detections to existing trackers using IoU + Hungarian algorithm\n",
    "        if len(trackers) == 0:\n",
    "            return np.empty((0,2),dtype=int), np.arange(len(detections)), np.empty((0),dtype=int)\n",
    "\n",
    "        iou_matrix = np.zeros((len(detections), len(trackers)), dtype=np.float32)\n",
    "        for d, det in enumerate(detections):\n",
    "            for t, trk in enumerate(trackers):\n",
    "                iou_matrix[d,t] = self.iou(det, trk)\n",
    "\n",
    "        matched_indices = linear_sum_assignment(-iou_matrix)\n",
    "        matched_indices = np.array(matched_indices).T\n",
    "        unmatched_detections = [d for d in range(len(detections)) if d not in matched_indices[:,0]]\n",
    "        unmatched_trackers = [t for t in range(len(trackers)) if t not in matched_indices[:,1]]\n",
    "\n",
    "        matches = []\n",
    "        for m in matched_indices:\n",
    "            if iou_matrix[m[0], m[1]] < 0.3:  # reject weak matches\n",
    "                unmatched_detections.append(m[0])\n",
    "                unmatched_trackers.append(m[1])\n",
    "            else:\n",
    "                matches.append(m.reshape(2))\n",
    "        return np.array(matches), np.array(unmatched_detections), np.array(unmatched_trackers)\n",
    "\n",
    "# --- Main video processing ---\n",
    "def process_video(video_path, model, output_dir):\n",
    "    # Create output directory\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Load video\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "    # Prepare output video and CSV paths\n",
    "    video_name = os.path.splitext(os.path.basename(video_path))[0]\n",
    "    out_vid_path = os.path.join(output_dir, f\"{video_name}_tracked.mp4\")\n",
    "    csv_path = os.path.join(output_dir, f\"{video_name}_tracking.csv\")\n",
    "\n",
    "    out = cv2.VideoWriter(out_vid_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (width, height))\n",
    "    csv_file = open(csv_path, 'w', newline='')\n",
    "    writer = csv.writer(csv_file)\n",
    "    writer.writerow(['frame', 'id', 'x1', 'y1', 'x2', 'y2'])\n",
    "\n",
    "    tracker = SORT()\n",
    "    frame_id = 0\n",
    "\n",
    "    # Process frames\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Run YOLO detection\n",
    "        results = model(frame)[0]\n",
    "        dets = [[x1, y1, x2, y2, conf] for x1, y1, x2, y2, conf, cls in results.boxes.data.tolist()\n",
    "                if conf > 0.4 and int(cls) == 0]  # class 0 = marmoset\n",
    "        dets = np.array(dets).reshape(-1, 5) if dets else np.empty((0,5))\n",
    "\n",
    "        # Update tracker with detections\n",
    "        tracked_objects = tracker.update(dets)\n",
    "\n",
    "        # Draw boxes + IDs, write CSV\n",
    "        for *bbox, tid in tracked_objects:\n",
    "            x1, y1, x2, y2 = map(int, bbox)\n",
    "            color = (0, 255, 0) if tid == 1 else (255, 0, 0)\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "            cv2.putText(frame, f'ID {tid}', (x1, y1-10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2)\n",
    "            writer.writerow([frame_id, tid, x1, y1, x2, y2])\n",
    "\n",
    "        out.write(frame)\n",
    "        frame_id += 1\n",
    "\n",
    "    # Cleanup\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    csv_file.close()\n",
    "\n",
    "def main():\n",
    "    # Input/output paths\n",
    "    video_dir = r\"D:\\DeepSORT_ML2025\\video_inputs\"\n",
    "    output_base_dir = r\"D:\\DeepSORT_ML2025\\video_outputs\"\n",
    "    model_path = r\"D:/DeepSORT_ML2025/yolo_project/marmoset_yolo/weights/best.pt\"\n",
    "\n",
    "    # Load YOLO model\n",
    "    model = YOLO(model_path)\n",
    "    os.makedirs(output_base_dir, exist_ok=True)\n",
    "\n",
    "    # Process all videos in directory\n",
    "    videos = glob.glob(os.path.join(video_dir, \"*.mp4\"))\n",
    "    for vid in videos:\n",
    "        print(f\"Processing {vid} ...\")\n",
    "        video_name = os.path.splitext(os.path.basename(vid))[0]\n",
    "        output_dir = os.path.join(output_base_dir, video_name)\n",
    "        process_video(vid, model, output_dir)\n",
    "        print(f\"Finished {video_name}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1b76e4",
   "metadata": {},
   "source": [
    "## The next few code blocks cater to the pre and post processing needs of a specific camera setup\n",
    "### When the arena is captured by 4 different cameras (Check the readme.md file associated with this repository for more details)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcd4d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import csv\n",
    "import math\n",
    "import glob\n",
    "import pandas as pd\n",
    "from ultralytics import YOLO\n",
    "from filterpy.kalman import KalmanFilter\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "# Inverse transform for right half boxes\n",
    "def inverse_transform_right_half_box(x1, y1, x2, y2):\n",
    "    inverse_transform_matrix = np.array([\n",
    "        [ 1.05403131,  0.12941877, -51.0827529],\n",
    "        [-0.14624321,  1.19105538, 136.228942],\n",
    "        [ 0.0,         0.0,          1.0     ]\n",
    "    ])\n",
    "\n",
    "    def apply_inverse(x, y):\n",
    "        pt = np.array([x, y, 1.0])\n",
    "        result = inverse_transform_matrix @ pt\n",
    "        return result[0], result[1]\n",
    "\n",
    "    x1n, y1n = apply_inverse(x1, y1)\n",
    "    x2n, y2n = apply_inverse(x2, y2)\n",
    "    return [x1n, y1n, x2n, y2n]\n",
    "\n",
    "# SORT tracker class\n",
    "class SORT:\n",
    "    def __init__(self):\n",
    "        self.trackers = []\n",
    "        self.used_ids = set()\n",
    "\n",
    "    class KalmanBoxTracker:\n",
    "        def __init__(self, bbox, assigned_id):\n",
    "            self.kf = KalmanFilter(dim_x=7, dim_z=4)\n",
    "            self.kf.F = np.array([\n",
    "                [1,0,0,0,1,0,0],\n",
    "                [0,1,0,0,0,1,0],\n",
    "                [0,0,1,0,0,0,1],\n",
    "                [0,0,0,1,0,0,0],\n",
    "                [0,0,0,0,1,0,0],\n",
    "                [0,0,0,0,0,1,0],\n",
    "                [0,0,0,0,0,0,1]])\n",
    "            self.kf.H = np.array([\n",
    "                [1,0,0,0,0,0,0],\n",
    "                [0,1,0,0,0,0,0],\n",
    "                [0,0,1,0,0,0,0],\n",
    "                [0,0,0,1,0,0,0]])\n",
    "            self.kf.R[2:,2:] *= 10.\n",
    "            self.kf.P[4:,4:] *= 1000.\n",
    "            self.kf.P *= 10.\n",
    "            self.kf.Q[-1,-1] *= 0.01\n",
    "            self.kf.Q[4:,4:] *= 0.01\n",
    "            cx, cy = (bbox[0]+bbox[2])/2, (bbox[1]+bbox[3])/2\n",
    "            s = (bbox[2]-bbox[0])*(bbox[3]-bbox[1])\n",
    "            r = (bbox[2]-bbox[0]) / (bbox[3]-bbox[1]+1e-6)\n",
    "            self.kf.x[:4] = np.array([cx, cy, s, r]).reshape((4,1))\n",
    "            self.id = assigned_id\n",
    "            self.time_since_update = 0\n",
    "            self.hits = 0\n",
    "            self.hit_streak = 0\n",
    "\n",
    "        def update(self, bbox):\n",
    "            cx, cy = (bbox[0]+bbox[2])/2, (bbox[1]+bbox[3])/2\n",
    "            s = (bbox[2]-bbox[0])*(bbox[3]-bbox[1])\n",
    "            r = (bbox[2]-bbox[0]) / (bbox[3]-bbox[1]+1e-6)\n",
    "            self.kf.update(np.array([cx, cy, s, r]).reshape((4,1)))\n",
    "            self.time_since_update = 0\n",
    "            self.hits += 1\n",
    "            self.hit_streak += 1\n",
    "\n",
    "        def predict(self):\n",
    "            self.kf.predict()\n",
    "            self.time_since_update += 1\n",
    "            if self.time_since_update > 0:\n",
    "                self.hit_streak = 0\n",
    "            return self.get_state()\n",
    "\n",
    "        def get_state(self):\n",
    "            cx, cy, s, r = self.kf.x[:4].reshape(-1)\n",
    "            w = np.sqrt(s*r)\n",
    "            h = s / (w + 1e-6)\n",
    "            return [cx-w/2, cy-h/2, cx+w/2, cy+h/2]\n",
    "\n",
    "    def assign_id(self):\n",
    "        for i in [1, 2]:\n",
    "            if i not in self.used_ids:\n",
    "                return i\n",
    "        return None\n",
    "\n",
    "    def update(self, detections):\n",
    "        # Predict new locations of existing trackers\n",
    "        trks = []\n",
    "        to_del = []\n",
    "        for t, trk in enumerate(self.trackers):\n",
    "            pos = trk.predict()\n",
    "            if np.any(np.isnan(pos)) or trk.time_since_update > 30:\n",
    "                to_del.append(t)\n",
    "            else:\n",
    "                trks.append(pos)\n",
    "\n",
    "        for t in reversed(to_del):\n",
    "            self.used_ids.discard(self.trackers[t].id)\n",
    "            self.trackers.pop(t)\n",
    "\n",
    "        trks = np.array(trks)\n",
    "        dets = detections[:, :4] if len(detections) > 0 else np.empty((0,4))\n",
    "\n",
    "        matched, unmatched_dets, unmatched_trks = self.associate_detections_to_trackers(dets, trks)\n",
    "\n",
    "        # Update matched trackers with assigned detections\n",
    "        for m in matched:\n",
    "            self.trackers[m[1]].update(detections[m[0], :4])\n",
    "\n",
    "        # Increment time_since_update for unmatched trackers\n",
    "        for t in unmatched_trks:\n",
    "            self.trackers[t].time_since_update += 1\n",
    "\n",
    "        # Create new trackers for unmatched detections (max 2 trackers)\n",
    "        for i in unmatched_dets:\n",
    "            if len(self.trackers) >= 2:\n",
    "                continue\n",
    "            new_id = self.assign_id()\n",
    "            if new_id is not None:\n",
    "                trk = SORT.KalmanBoxTracker(detections[i, :4], new_id)\n",
    "                self.trackers.append(trk)\n",
    "                self.used_ids.add(new_id)\n",
    "\n",
    "        ret = []\n",
    "        for trk in self.trackers:\n",
    "            if trk.time_since_update < 1 and (trk.hits >= 3 or len(self.trackers) <= 2):\n",
    "                d = trk.get_state()\n",
    "                ret.append([*d, trk.id])\n",
    "        return ret\n",
    "\n",
    "    def iou(self, bb_test, bb_gt):\n",
    "        xx1 = np.maximum(bb_test[0], bb_gt[0])\n",
    "        yy1 = np.maximum(bb_test[1], bb_gt[1])\n",
    "        xx2 = np.minimum(bb_test[2], bb_gt[2])\n",
    "        yy2 = np.minimum(bb_test[3], bb_gt[3])\n",
    "        w = np.maximum(0., xx2 - xx1)\n",
    "        h = np.maximum(0., yy2 - yy1)\n",
    "        wh = w*h\n",
    "        o = wh / ((bb_test[2]-bb_test[0])*(bb_test[3]-bb_test[1]) + (bb_gt[2]-bb_gt[0])*(bb_gt[3]-bb_gt[1]) - wh + 1e-6)\n",
    "        return o\n",
    "\n",
    "    def associate_detections_to_trackers(self, detections, trackers):\n",
    "        if len(trackers) == 0:\n",
    "            return np.empty((0,2),dtype=int), np.arange(len(detections)), np.empty((0),dtype=int)\n",
    "\n",
    "        iou_matrix = np.zeros((len(detections), len(trackers)), dtype=np.float32)\n",
    "        for d, det in enumerate(detections):\n",
    "            for t, trk in enumerate(trackers):\n",
    "                iou_matrix[d,t] = self.iou(det, trk)\n",
    "\n",
    "        matched_indices = linear_sum_assignment(-iou_matrix)\n",
    "        matched_indices = np.array(matched_indices).T\n",
    "\n",
    "        unmatched_detections = [d for d in range(len(detections)) if d not in matched_indices[:,0]]\n",
    "        unmatched_trackers = [t for t in range(len(trackers)) if t not in matched_indices[:,1]]\n",
    "\n",
    "        matches = []\n",
    "        for m in matched_indices:\n",
    "            if iou_matrix[m[0], m[1]] < 0.3:\n",
    "                unmatched_detections.append(m[0])\n",
    "                unmatched_trackers.append(m[1])\n",
    "            else:\n",
    "                matches.append(m.reshape(2))\n",
    "\n",
    "        return np.array(matches), np.array(unmatched_detections), np.array(unmatched_trackers)\n",
    "\n",
    "# Log helper for ID 1 left/right position by column (x1 or x2)\n",
    "def log_id1_position(df, colname, txt_path, width):\n",
    "    log_lines = []\n",
    "    for fid, group in df.groupby(\"frame\"):\n",
    "        pos = {}\n",
    "        for tid in [1, 2]:\n",
    "            sub = group[(group['id'] == tid) & (~group[colname].isna())]\n",
    "            if sub.empty:\n",
    "                continue\n",
    "            val = sub[colname].iloc[0]\n",
    "            if sub['side'].iloc[0] == 'right':\n",
    "                val += width // 2\n",
    "            pos[tid] = val\n",
    "        if 1 in pos and 2 in pos:\n",
    "            where = 'left' if pos[1] < pos[2] else 'right'\n",
    "            log_lines.append(f\"Frame {fid}: ID 1 is on the {where}\")\n",
    "    with open(txt_path, 'w') as f:\n",
    "        f.write('\\n'.join(log_lines))\n",
    "\n",
    "# Main video processing function\n",
    "def process_video(video_path, model, output_dir):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    center_x = width // 2\n",
    "\n",
    "    video_name = os.path.splitext(os.path.basename(video_path))[0]\n",
    "\n",
    "    # Paths for outputs\n",
    "    out_vid_path = os.path.join(output_dir, f\"{video_name}_tracked.mp4\")\n",
    "    combined_csv_path = os.path.join(output_dir, f\"{video_name}_tracking.csv\")\n",
    "    left_csv_path = os.path.join(output_dir, f\"{video_name}_cam10.csv\")\n",
    "    right_csv_path = os.path.join(output_dir, f\"{video_name}_cam11.csv\")\n",
    "    txt_x1_path = os.path.join(output_dir, f\"{video_name}_id1_x1_position.txt\")\n",
    "    txt_x2_path = os.path.join(output_dir, f\"{video_name}_id1_x2_position.txt\")\n",
    "\n",
    "    # Video writer\n",
    "    out = cv2.VideoWriter(out_vid_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (width, height))\n",
    "\n",
    "    # CSV writers\n",
    "    combined_csv_file = open(combined_csv_path, 'w', newline='')\n",
    "    combined_writer = csv.writer(combined_csv_file)\n",
    "    combined_writer.writerow(['frame', 'side', 'id', 'x1', 'y1', 'x2', 'y2'])\n",
    "\n",
    "    left_csv_file = open(left_csv_path, 'w', newline='')\n",
    "    left_writer = csv.writer(left_csv_file)\n",
    "    left_writer.writerow(['frame', 'id', 'x1', 'y1', 'x2', 'y2'])\n",
    "\n",
    "    right_csv_file = open(right_csv_path, 'w', newline='')\n",
    "    right_writer = csv.writer(right_csv_file)\n",
    "    right_writer.writerow(['frame', 'id', 'x1', 'y1', 'x2', 'y2'])\n",
    "\n",
    "    tracker = SORT()\n",
    "    frame_id = 0\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        results = model(frame)[0]\n",
    "        dets = [[x1, y1, x2, y2, conf] for x1, y1, x2, y2, conf, cls in results.boxes.data.tolist()\n",
    "                if conf > 0.4 and int(cls) == 0]\n",
    "        dets = np.array(dets).reshape(-1, 5) if dets else np.empty((0,5))\n",
    "\n",
    "        tracked_objects = tracker.update(dets)\n",
    "\n",
    "        # Store left and right side boxes per ID for this frame\n",
    "        sides = {'left': {1: None, 2: None}, 'right': {1: None, 2: None}}\n",
    "\n",
    "        # YOUR FULL MODIFIED SCRIPT (with drawing logic changed)\n",
    "# This version keeps inverse-transformed right boxes in CSVs,\n",
    "# but uses YOLO-detected raw boxes for drawing in the video.\n",
    "\n",
    "# [all your imports, tracker code, etc. remains unchanged above this line]\n",
    "\n",
    "# Replace the drawing logic INSIDE `process_video()` with this:\n",
    "        for *bbox, tid in tracked_objects:\n",
    "            x1, y1, x2, y2 = bbox\n",
    "            x1_i, y1_i, x2_i, y2_i = map(int, bbox)\n",
    "\n",
    "            if x1_i < center_x < x2_i:\n",
    "                # Left side clipped to center\n",
    "                left_box = (x1_i, y1_i, center_x, y2_i)\n",
    "                right_box_rel = (0, y1_i, x2_i - center_x, y2_i)\n",
    "                right_box = inverse_transform_right_half_box(*right_box_rel)\n",
    "\n",
    "                sides['left'][tid] = left_box\n",
    "                sides['right'][tid] = right_box\n",
    "\n",
    "                # Choose colors per ID\n",
    "                color = (0, 255, 0) if tid == 1 else (255, 0, 0)  # Green for ID1, Blue for ID2\n",
    "\n",
    "                # Draw raw YOLO boxes (split)\n",
    "                cv2.rectangle(frame, (x1_i, y1_i), (center_x, y2_i), color, 2)\n",
    "                cv2.putText(frame, f'ID {tid}', (x1_i, y1_i-10),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2)\n",
    "                cv2.rectangle(frame, (center_x, y1_i), (x2_i, y2_i), color, 2)\n",
    "                cv2.putText(frame, f'ID {tid}', (center_x, y1_i-10),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2)\n",
    "\n",
    "            elif x2_i <= center_x:\n",
    "                # Fully on left\n",
    "                sides['left'][tid] = (x1_i, y1_i, x2_i, y2_i)\n",
    "                color = (0, 255, 0) if tid == 1 else (255, 0, 0)\n",
    "                cv2.rectangle(frame, (x1_i, y1_i), (x2_i, y2_i), color, 2)\n",
    "                cv2.putText(frame, f'ID {tid}', (x1_i, y1_i-10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2)\n",
    "\n",
    "            else:\n",
    "                # Fully on right: apply inverse for CSV, but draw original\n",
    "                right_box_rel = (x1_i - center_x, y1_i, x2_i - center_x, y2_i)\n",
    "                right_box = inverse_transform_right_half_box(*right_box_rel)\n",
    "                sides['right'][tid] = right_box\n",
    "\n",
    "                color = (0, 255, 0) if tid == 1 else (255, 0, 0)\n",
    "                cv2.rectangle(frame, (x1_i, y1_i), (x2_i, y2_i), color, 2)\n",
    "                cv2.putText(frame, f'ID {tid}', (x1_i, y1_i-10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2)\n",
    "\n",
    "\n",
    "        # Write bounding box info to CSVs\n",
    "        for side in ['left', 'right']:\n",
    "            for tid in [1, 2]:\n",
    "                box = sides[side][tid]\n",
    "                if box is None:\n",
    "                    combined_writer.writerow([frame_id, side, tid, np.nan, np.nan, np.nan, np.nan])\n",
    "                    if side == 'left':\n",
    "                        left_writer.writerow([frame_id, tid, np.nan, np.nan, np.nan, np.nan])\n",
    "                    else:\n",
    "                        right_writer.writerow([frame_id, tid, np.nan, np.nan, np.nan, np.nan])\n",
    "                else:\n",
    "                    x1, y1, x2, y2 = box\n",
    "                    combined_writer.writerow([frame_id, side, tid, x1, y1, x2, y2])\n",
    "                    if side == 'left':\n",
    "                        left_writer.writerow([frame_id, tid, x1, y1, x2, y2])\n",
    "                    else:\n",
    "                        right_writer.writerow([frame_id, tid, x1, y1, x2, y2])\n",
    "\n",
    "        out.write(frame)\n",
    "        frame_id += 1\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    combined_csv_file.close()\n",
    "    left_csv_file.close()\n",
    "    right_csv_file.close()\n",
    "\n",
    "    # Load combined CSV to generate TXT logs for x1 and x2\n",
    "    df = pd.read_csv(combined_csv_path)\n",
    "    log_id1_position(df, 'x1', txt_x1_path, width)\n",
    "    log_id1_position(df, 'x2', txt_x2_path, width)\n",
    "\n",
    "# Batch processing for all videos in folder\n",
    "def main():\n",
    "    video_dir = r\"D:\\DeepSORT_ML2025\\video_stitch\\stitched_outputs\"\n",
    "    output_base_dir = r\"D:\\DeepSORT_ML2025\\video_stitch\\cam10_cam11_tracked\"\n",
    "    model_path = r\"D:/DeepSORT_ML2025/yolo_project/marmoset_yolo_20250619_172321/weights/best.pt\"\n",
    "\n",
    "    model = YOLO(model_path)\n",
    "\n",
    "    os.makedirs(output_base_dir, exist_ok=True)\n",
    "    videos = glob.glob(os.path.join(video_dir, \"*.mp4\"))\n",
    "\n",
    "    for vid in videos:\n",
    "        print(f\"Processing {vid} ...\")\n",
    "        video_name = os.path.splitext(os.path.basename(vid))[0]\n",
    "        output_dir = os.path.join(output_base_dir, video_name)\n",
    "        process_video(vid, model, output_dir)\n",
    "        print(f\"Finished {video_name}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b18e96",
   "metadata": {},
   "source": [
    "### make empty txt in all subfolders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e7361e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# === Path to your target root folder ===\n",
    "target_root = r\"D:\\DeepSORT_ML2025\\video_stitch\\cam10_cam11_tracked\"\n",
    "\n",
    "# === Go through all subfolders ===\n",
    "for subfolder in os.listdir(target_root):\n",
    "    subfolder_path = os.path.join(target_root, subfolder)\n",
    "\n",
    "    # Ensure it's a directory\n",
    "    if os.path.isdir(subfolder_path):\n",
    "        close_file = os.path.join(subfolder_path, 'close_frames.txt')\n",
    "\n",
    "        # Create the file if it doesn't exist\n",
    "        if not os.path.exists(close_file):\n",
    "            with open(close_file, 'w') as f:\n",
    "                f.write('')  # Optional: add a header like 'Close Frames:\\n'\n",
    "            print(f'Created: {close_file}')\n",
    "        else:\n",
    "            print(f'Already exists: {close_file}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ad7832",
   "metadata": {},
   "source": [
    "### Switching IDs from Manual Guide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5485ce00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Convert close_frames.txt to a list of (start_frame, end_frame)\n",
    "def parse_swap_file(txt_path, fps=24):\n",
    "    swaps = []\n",
    "    with open(txt_path, 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            if '-' in line:\n",
    "                start_sec, end_sec = map(float, line.split('-'))\n",
    "                swaps.append((int(start_sec * fps), int(end_sec * fps)))\n",
    "            else:\n",
    "                start_frame = int(float(line) * fps)\n",
    "                swaps.append((start_frame, float('inf')))\n",
    "    return swaps\n",
    "\n",
    "# Check if a given frame is in any swap range\n",
    "def should_swap(frame, swap_ranges):\n",
    "    return any(start <= frame <= end for start, end in swap_ranges)\n",
    "\n",
    "# Swap ID 1 and 2 in the tracking CSV\n",
    "def correct_csv(csv_path, swap_ranges):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    for i, row in df.iterrows():\n",
    "        frame = row['frame']\n",
    "        if should_swap(frame, swap_ranges):\n",
    "            old_id = df.at[i, 'id']\n",
    "            if pd.notna(old_id):\n",
    "                df.at[i, 'id'] = 3 - old_id  # Swap 1 ↔ 2\n",
    "    return df\n",
    "\n",
    "# Swap \"ID 1 is on the left/right\" lines in log files\n",
    "def correct_log(log_path, swap_ranges):\n",
    "    corrected_lines = []\n",
    "    with open(log_path, 'r') as f:\n",
    "        for line in f:\n",
    "            match = re.search(r'Frame (\\d+): ID 1 is on the (\\w+)', line)\n",
    "            if match:\n",
    "                frame = int(match.group(1))\n",
    "                side = match.group(2)\n",
    "                if should_swap(frame, swap_ranges):\n",
    "                    side = 'right' if side == 'left' else 'left'\n",
    "                corrected_lines.append(f\"Frame {frame}: ID 1 is on the {side}\")\n",
    "            else:\n",
    "                corrected_lines.append(line.strip())\n",
    "    return corrected_lines\n",
    "\n",
    "# Process one folder\n",
    "def process_folder(folder, fps=24):\n",
    "    print(f\"Processing: {folder}\")\n",
    "    close_path = os.path.join(folder, \"close_frames.txt\")\n",
    "    if not os.path.exists(close_path):\n",
    "        print(\"  Skipping (no close_frames.txt found)\")\n",
    "        return\n",
    "\n",
    "    base = None\n",
    "    for file in os.listdir(folder):\n",
    "        if file.endswith(\"_tracking.csv\"):\n",
    "            base = file.replace(\"_tracking.csv\", \"\")\n",
    "            break\n",
    "    if not base:\n",
    "        print(\"  Skipping (no tracking CSV found)\")\n",
    "        return\n",
    "\n",
    "    swap_ranges = parse_swap_file(close_path, fps)\n",
    "\n",
    "    # Fix CSV\n",
    "    csv_path = os.path.join(folder, f\"{base}_tracking.csv\")\n",
    "    df = correct_csv(csv_path, swap_ranges)\n",
    "    df.to_csv(os.path.join(folder, f\"{base}_tracking_corrected.csv\"), index=False)\n",
    "\n",
    "    # Fix log TXT files\n",
    "    for axis in [\"x1\", \"x2\"]:\n",
    "        txt_path = os.path.join(folder, f\"{base}_id1_{axis}_position.txt\")\n",
    "        if os.path.exists(txt_path):\n",
    "            corrected_lines = correct_log(txt_path, swap_ranges)\n",
    "            corrected_path = os.path.join(folder, f\"{base}_id1_{axis}_position_corrected.txt\")\n",
    "            with open(corrected_path, 'w') as f:\n",
    "                f.write(\"\\n\".join(corrected_lines))\n",
    "\n",
    "# Process all video folders\n",
    "def main():\n",
    "    root_dir = r\"D:\\tracked_output\"  # update if needed\n",
    "    for subfolder in os.listdir(root_dir):\n",
    "        full_path = os.path.join(root_dir, subfolder)\n",
    "        if os.path.isdir(full_path):\n",
    "            process_folder(full_path)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f9e91c",
   "metadata": {},
   "source": [
    "### Creating files after correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2087cd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import re\n",
    "\n",
    "def load_switch_intervals(txt_path, total_frames, fps=24):\n",
    "    intervals = []\n",
    "    with open(txt_path, 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            if '-' in line:\n",
    "                start_sec, end_sec = line.split('-')\n",
    "                start_frame = int(float(start_sec) * fps)\n",
    "                end_frame = int(float(end_sec) * fps)\n",
    "            else:\n",
    "                start_frame = int(float(line) * fps)\n",
    "                end_frame = total_frames - 1\n",
    "            start_frame = max(0, start_frame)\n",
    "            end_frame = min(total_frames - 1, end_frame)\n",
    "            intervals.append((start_frame, end_frame))\n",
    "    return intervals\n",
    "\n",
    "def get_fps_and_framecount(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    total = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    cap.release()\n",
    "    return fps, total\n",
    "\n",
    "def swap_ids_in_df(df, intervals):\n",
    "    df = df.copy()\n",
    "    for start, end in intervals:\n",
    "        mask = (df['frame'] >= start) & (df['frame'] <= end)\n",
    "        id1_rows = df[mask & (df['id'] == 1)].index\n",
    "        id2_rows = df[mask & (df['id'] == 2)].index\n",
    "\n",
    "        # Temporarily mark id=1 rows as -1 to avoid collision\n",
    "        df.loc[id1_rows, 'id'] = -1\n",
    "        df.loc[id2_rows, 'id'] = 1\n",
    "        df.loc[id1_rows, 'id'] = 2\n",
    "\n",
    "        # Swap bbox coords between these rows per frame\n",
    "        frames_to_swap = df.loc[mask, 'frame'].unique()\n",
    "        for f in frames_to_swap:\n",
    "            idx1 = df[(df['frame'] == f) & (df['id'] == 2)].index\n",
    "            idx2 = df[(df['frame'] == f) & (df['id'] == 1)].index\n",
    "            if len(idx1) == 1 and len(idx2) == 1:\n",
    "                cols = ['x1', 'y1', 'x2', 'y2']\n",
    "                tmp = df.loc[idx1[0], cols].copy()\n",
    "                df.loc[idx1[0], cols] = df.loc[idx2[0], cols]\n",
    "                df.loc[idx2[0], cols] = tmp\n",
    "    return df\n",
    "\n",
    "def swap_sides_in_txt(lines, intervals, fps=24):\n",
    "    new_lines = []\n",
    "    for line in lines:\n",
    "        # Check if line starts with \"Frame N:\"\n",
    "        m = re.match(r\"Frame\\s+(\\d+):\\s+ID\\s+1\\s+is\\s+on\\s+the\\s+(left|right)\", line)\n",
    "        if m:\n",
    "            frame_num = int(m.group(1))\n",
    "            side = m.group(2)\n",
    "            # Check if this frame is in any switch interval\n",
    "            if any(start <= frame_num <= end for start, end in intervals):\n",
    "                flipped_side = 'left' if side == 'right' else 'right'\n",
    "                line = re.sub(r\"(left|right)\", flipped_side, line)\n",
    "        new_lines.append(line)\n",
    "    return new_lines\n",
    "\n",
    "def process_folder(sub_path):\n",
    "    print(f\"\\nProcessing folder: {sub_path}\")\n",
    "    video_file = [f for f in os.listdir(sub_path) if f.endswith('.mp4')]\n",
    "    if not video_file:\n",
    "        print(\"  No video file found, skipping.\")\n",
    "        return\n",
    "    video_file = video_file[0]\n",
    "    video_path = os.path.join(sub_path, video_file)\n",
    "    fps, total_frames = get_fps_and_framecount(video_path)\n",
    "\n",
    "    close_frames_path = os.path.join(sub_path, 'close_frames.txt')\n",
    "    if not os.path.exists(close_frames_path):\n",
    "        print(\"  No close_frames.txt found, skipping.\")\n",
    "        return\n",
    "\n",
    "    intervals = load_switch_intervals(close_frames_path, total_frames, fps)\n",
    "    if not intervals:\n",
    "        print(\"  No intervals to switch found.\")\n",
    "        return\n",
    "\n",
    "    print(f\"  Switch intervals (frames): {intervals}\")\n",
    "\n",
    "    base_name = os.path.basename(sub_path)\n",
    "\n",
    "    # Process CSV files\n",
    "    csv_files = [f for f in os.listdir(sub_path) if f.endswith('.csv') and not f.endswith('_corrected.csv')]\n",
    "    for csv_file in csv_files:\n",
    "        csv_path = os.path.join(sub_path, csv_file)\n",
    "        df = pd.read_csv(csv_path)\n",
    "        required_cols = {'frame','id','x1','y1','x2','y2'}\n",
    "        if not required_cols.issubset(df.columns):\n",
    "            print(f\"  Skipping {csv_file}, missing required columns.\")\n",
    "            continue\n",
    "        print(f\"  Processing CSV: {csv_file}\")\n",
    "        df_corrected = swap_ids_in_df(df, intervals)\n",
    "        corrected_path = os.path.join(sub_path, csv_file.replace('.csv', '_corrected.csv'))\n",
    "        df_corrected.to_csv(corrected_path, index=False)\n",
    "        print(f\"    Saved corrected CSV: {corrected_path}\")\n",
    "\n",
    "    # Process TXT files\n",
    "    txt_files = [f for f in os.listdir(sub_path) if f.endswith('.txt') and not f.endswith('_corrected.txt') and 'close_frames' not in f]\n",
    "    for txt_file in txt_files:\n",
    "        txt_path = os.path.join(sub_path, txt_file)\n",
    "        with open(txt_path, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "        print(f\"  Processing TXT: {txt_file}\")\n",
    "        lines_corrected = swap_sides_in_txt(lines, intervals, fps)\n",
    "        corrected_txt_path = os.path.join(sub_path, txt_file.replace('.txt', '_corrected.txt'))\n",
    "        with open(corrected_txt_path, 'w') as f:\n",
    "            f.writelines(lines_corrected)\n",
    "        print(f\"    Saved corrected TXT: {corrected_txt_path}\")\n",
    "\n",
    "def main():\n",
    "    root_dir = r\"D:\\DeepSORT_ML2025\\video_stitch\\cam10_cam11_tracked\"  # Change this to your root folder\n",
    "    for folder in sorted(os.listdir(root_dir)):\n",
    "        sub_path = os.path.join(root_dir, folder)\n",
    "        if os.path.isdir(sub_path):\n",
    "            process_folder(sub_path)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc80338",
   "metadata": {},
   "source": [
    "### Tracking cam18 with guide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9da29ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import csv\n",
    "from ultralytics import YOLO\n",
    "from filterpy.kalman import KalmanFilter\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "\n",
    "def load_guide_txt(txt_path):\n",
    "    guide = {}\n",
    "    with open(txt_path, 'r') as f:\n",
    "        for line in f:\n",
    "            if \"Frame\" in line and \"ID 1 is on the\" in line:\n",
    "                parts = line.strip().split(\":\")\n",
    "                frame_num = int(parts[0].split()[-1])\n",
    "                side = parts[1].strip().split()[-1].lower()\n",
    "                guide[frame_num] = side\n",
    "    return guide\n",
    "\n",
    "\n",
    "class KalmanBoxTracker:\n",
    "    def __init__(self, bbox, assigned_id):\n",
    "        self.kf = KalmanFilter(dim_x=7, dim_z=4)\n",
    "        self.kf.F = np.eye(7)\n",
    "        self.kf.F[:4, 4:] = np.eye(4)[:4, :3]\n",
    "        self.kf.H = np.eye(4, 7)\n",
    "        self.kf.P[4:, 4:] *= 1000.\n",
    "        self.kf.P *= 10.\n",
    "        self.kf.Q *= 0.001\n",
    "\n",
    "        cx = (bbox[0] + bbox[2]) / 2\n",
    "        cy = (bbox[1] + bbox[3]) / 2\n",
    "        s = (bbox[2] - bbox[0]) * (bbox[3] - bbox[1])\n",
    "        r = (bbox[2] - bbox[0]) / (bbox[3] - bbox[1] + 1e-6)\n",
    "        self.kf.x[:4] = np.array([cx, cy, s, r]).reshape((4, 1))\n",
    "\n",
    "        self.id = assigned_id\n",
    "        self.hits = 1\n",
    "        self.time_since_update = 0\n",
    "        self.last_yolo_box = bbox\n",
    "\n",
    "    def predict(self):\n",
    "        self.kf.predict()\n",
    "        self.time_since_update += 1\n",
    "        return self.get_state()\n",
    "\n",
    "    def update(self, bbox):\n",
    "        self.time_since_update = 0\n",
    "        self.hits += 1\n",
    "        cx = (bbox[0] + bbox[2]) / 2\n",
    "        cy = (bbox[1] + bbox[3]) / 2\n",
    "        s = (bbox[2] - bbox[0]) * (bbox[3] - bbox[1])\n",
    "        r = (bbox[2] - bbox[0]) / (bbox[3] - bbox[1] + 1e-6)\n",
    "        self.kf.update(np.array([cx, cy, s, r]).reshape((4, 1)))\n",
    "        self.last_yolo_box = bbox\n",
    "\n",
    "    def get_state(self):\n",
    "        cx, cy, s, r = self.kf.x[:4].reshape(-1)\n",
    "        if s * r <= 0:\n",
    "            return [0, 0, 0, 0]\n",
    "        w = np.sqrt(abs(s * r))\n",
    "        h = abs(s) / (w + 1e-6)\n",
    "        return [cx - w / 2, cy - h / 2, cx + w / 2, cy + h / 2]\n",
    "\n",
    "\n",
    "class SORT:\n",
    "    def __init__(self, guide):\n",
    "        self.trackers = []\n",
    "        self.frame_id = 0\n",
    "        self.guide = guide\n",
    "\n",
    "    def update(self, detections, width):\n",
    "        self.frame_id += 1\n",
    "        updated_tracks = []\n",
    "\n",
    "        detections = sorted(detections, key=lambda d: d[4], reverse=True)[:2]\n",
    "        det_boxes = [d[:4] for d in detections]\n",
    "\n",
    "        guide_side = self.guide.get(self.frame_id - 1)\n",
    "\n",
    "        if guide_side and det_boxes:\n",
    "            self.trackers = []\n",
    "            if len(det_boxes) == 1:\n",
    "                assigned_id = 1 if guide_side == 'left' else 2\n",
    "                self.trackers = [KalmanBoxTracker(det_boxes[0], assigned_id)]\n",
    "                updated_tracks.append([*det_boxes[0], assigned_id])\n",
    "            elif len(det_boxes) == 2:\n",
    "                sorted_dets = sorted(det_boxes, key=lambda b: b[0])\n",
    "                ids = [1, 2] if guide_side == 'left' else [2, 1]\n",
    "                for i in range(2):\n",
    "                    trk = KalmanBoxTracker(sorted_dets[i], ids[i])\n",
    "                    self.trackers.append(trk)\n",
    "                    updated_tracks.append([*sorted_dets[i], ids[i]])\n",
    "\n",
    "        return updated_tracks\n",
    "\n",
    "\n",
    "def track_video(video_path, guide_path, output_dir, model):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    guide = load_guide_txt(guide_path)\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "    base = os.path.splitext(os.path.basename(video_path))[0]\n",
    "    out_path = os.path.join(output_dir, f\"{base}_tracked.mp4\")\n",
    "    csv_path = os.path.join(output_dir, f\"{base}_tracking.csv\")\n",
    "\n",
    "    out = cv2.VideoWriter(out_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (width, height))\n",
    "    tracker = SORT(guide)\n",
    "\n",
    "    csv_file = open(csv_path, 'w', newline='')\n",
    "    csv_writer = csv.writer(csv_file)\n",
    "    csv_writer.writerow(['frame', 'id', 'x1', 'y1', 'x2', 'y2'])\n",
    "\n",
    "    frame_idx = 0\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        results = model(frame, verbose=False)[0]\n",
    "        dets = [[*xyxy, conf] for *xyxy, conf, cls in results.boxes.data.tolist()\n",
    "                if conf > 0.7 and int(cls) == 0]\n",
    "\n",
    "        tracks = tracker.update(dets, width)\n",
    "\n",
    "        for x1, y1, x2, y2, tid in tracks:\n",
    "            x1i, y1i, x2i, y2i = map(int, [x1, y1, x2, y2])\n",
    "            color = (255, 0, 0) if tid == 1 else (0, 255, 0)\n",
    "            cv2.rectangle(frame, (x1i, y1i), (x2i, y2i), color, 2)\n",
    "            cv2.putText(frame, f'ID {tid}', (x1i, y1i - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "            csv_writer.writerow([frame_idx, tid, x1, y1, x2, y2])\n",
    "\n",
    "        out.write(frame)\n",
    "        frame_idx += 1\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    csv_file.close()\n",
    "    print(f\"✓ Finished: {video_path}\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    video_dir = r\"D:\\DeepSORT_ML2025\\video_stitch\\cam18\" \n",
    "    guide_root_dir = r\"D:\\DeepSORT_ML2025\\video_stitch\\cam10_cam11_tracked\" \n",
    "    output_dir = r\"D:\\DeepSORT_ML2025\\video_stitch\\cam18_tracked\" \n",
    "\n",
    "    model_path = r\"D:\\DeepSORT_ML2025\\yolo_project\\marmoset_yolo_20250708_105031\\weights\\best.pt\" \n",
    "    model = YOLO(model_path)\n",
    "\n",
    "    for fname in os.listdir(video_dir):\n",
    "        if not fname.endswith(\".mp4\"):\n",
    "            continue\n",
    "        if \"cam15\" not in fname and \"cam18\" not in fname:\n",
    "            continue\n",
    "\n",
    "        full_path = os.path.join(video_dir, fname)\n",
    "        base_name = fname.replace(\"_cam15_\", \"\").replace(\"_cam18_\", \"\").replace(\"__\", \"_\").replace(\"--\", \"-\")\n",
    "        base_name = os.path.splitext(base_name)[0]\n",
    "\n",
    "        guide_path = os.path.join(guide_root_dir, base_name, f\"{base_name}_id1_x1_position_corrected.txt\")\n",
    "        if not os.path.exists(guide_path):\n",
    "            print(f\"⚠️ Guide not found: {guide_path}\")\n",
    "            continue\n",
    "\n",
    "                # Remove common suffix patterns like _from_18_pre or _from_18_post\n",
    "        clean_base_name = base_name.split(\"_from_\")[0]\n",
    "        video_output_dir = os.path.join(output_dir, clean_base_name)\n",
    "\n",
    "        track_video(full_path, guide_path, video_output_dir, model)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18594dd",
   "metadata": {},
   "source": [
    "### Tracking cam15 with guide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6383a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import csv\n",
    "from ultralytics import YOLO\n",
    "from filterpy.kalman import KalmanFilter\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "# Load guide TXT \n",
    "def load_guide_txt(txt_path):\n",
    "    guide = {}\n",
    "    with open(txt_path, 'r') as f:\n",
    "        for line in f:\n",
    "            if \"Frame\" in line and \"ID 1 is on the\" in line:\n",
    "                parts = line.strip().split(\":\")\n",
    "                frame_num = int(parts[0].split()[-1])\n",
    "                side = parts[1].strip().split()[-1].lower()\n",
    "                guide[frame_num] = side\n",
    "    return guide\n",
    "\n",
    "# Kalman Tracker \n",
    "class KalmanBoxTracker:\n",
    "    def __init__(self, bbox, assigned_id):\n",
    "        self.kf = KalmanFilter(dim_x=7, dim_z=4)\n",
    "        self.kf.F = np.eye(7)\n",
    "        self.kf.F[:4, 4:] = np.eye(4)[:4, :3]\n",
    "        self.kf.H = np.eye(4, 7)\n",
    "        self.kf.P[4:, 4:] *= 1000.\n",
    "        self.kf.P *= 10.\n",
    "        self.kf.Q *= 0.001\n",
    "\n",
    "        cx = (bbox[0] + bbox[2]) / 2\n",
    "        cy = (bbox[1] + bbox[3]) / 2\n",
    "        s = (bbox[2] - bbox[0]) * (bbox[3] - bbox[1])\n",
    "        r = (bbox[2] - bbox[0]) / (bbox[3] - bbox[1] + 1e-6)\n",
    "        self.kf.x[:4] = np.array([cx, cy, s, r]).reshape((4, 1))\n",
    "\n",
    "        self.id = assigned_id\n",
    "        self.hits = 1\n",
    "        self.time_since_update = 0\n",
    "        self.last_yolo_box = bbox\n",
    "\n",
    "    def predict(self):\n",
    "        self.kf.predict()\n",
    "        self.time_since_update += 1\n",
    "        return self.get_state()\n",
    "\n",
    "    def update(self, bbox):\n",
    "        self.time_since_update = 0\n",
    "        self.hits += 1\n",
    "        cx = (bbox[0] + bbox[2]) / 2\n",
    "        cy = (bbox[1] + bbox[3]) / 2\n",
    "        s = (bbox[2] - bbox[0]) * (bbox[3] - bbox[1])\n",
    "        r = (bbox[2] - bbox[0]) / (bbox[3] - bbox[1] + 1e-6)\n",
    "        self.kf.update(np.array([cx, cy, s, r]).reshape((4, 1)))\n",
    "        self.last_yolo_box = bbox\n",
    "\n",
    "    def get_state(self):\n",
    "        cx, cy, s, r = self.kf.x[:4].reshape(-1)\n",
    "        if s * r <= 0:\n",
    "            return [0, 0, 0, 0]\n",
    "        w = np.sqrt(abs(s * r))\n",
    "        h = abs(s) / (w + 1e-6)\n",
    "        return [cx - w / 2, cy - h / 2, cx + w / 2, cy + h / 2]\n",
    "\n",
    "#SORT Tracker \n",
    "class SORT:\n",
    "    def __init__(self, guide):\n",
    "        self.trackers = []\n",
    "        self.frame_id = 0\n",
    "        self.guide = guide\n",
    "\n",
    "    def update(self, detections):\n",
    "        self.frame_id += 1\n",
    "        updated_tracks = []\n",
    "\n",
    "        detections = sorted(detections, key=lambda d: d[4], reverse=True)[:2]\n",
    "        det_boxes = [d[:4] for d in detections]\n",
    "\n",
    "        guide_side = self.guide.get(self.frame_id - 1)\n",
    "\n",
    "        if guide_side and det_boxes:\n",
    "            self.trackers = []\n",
    "            if len(det_boxes) == 1:\n",
    "                assigned_id = 1 if guide_side == 'right' else 2\n",
    "                self.trackers = [KalmanBoxTracker(det_boxes[0], assigned_id)]\n",
    "                updated_tracks.append([*det_boxes[0], assigned_id])\n",
    "            elif len(det_boxes) == 2:\n",
    "                sorted_dets = sorted(det_boxes, key=lambda b: b[2], reverse=True)  # Sort by x2\n",
    "                ids = [1, 2] if guide_side == 'right' else [2, 1]\n",
    "                for i in range(2):\n",
    "                    trk = KalmanBoxTracker(sorted_dets[i], ids[i])\n",
    "                    self.trackers.append(trk)\n",
    "                    updated_tracks.append([*sorted_dets[i], ids[i]])\n",
    "\n",
    "        return updated_tracks\n",
    "\n",
    "# Run tracking on one video\n",
    "def track_video(video_path, guide_path, output_dir, model):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    guide = load_guide_txt(guide_path)\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "    base = os.path.splitext(os.path.basename(video_path))[0]\n",
    "    out_path = os.path.join(output_dir, f\"{base}_tracked.mp4\")\n",
    "    csv_path = os.path.join(output_dir, f\"{base}_tracking.csv\")\n",
    "\n",
    "    out = cv2.VideoWriter(out_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (width, height))\n",
    "    tracker = SORT(guide)\n",
    "\n",
    "    csv_file = open(csv_path, 'w', newline='')\n",
    "    csv_writer = csv.writer(csv_file)\n",
    "    csv_writer.writerow(['frame', 'id', 'x1', 'y1', 'x2', 'y2'])\n",
    "\n",
    "    frame_idx = 0\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        results = model(frame, verbose=False)[0]\n",
    "        dets = [[*xyxy, conf] for *xyxy, conf, cls in results.boxes.data.tolist()\n",
    "                if conf > 0.7 and int(cls) == 0]\n",
    "\n",
    "        tracks = tracker.update(dets)\n",
    "\n",
    "        for x1, y1, x2, y2, tid in tracks:\n",
    "            x1i, y1i, x2i, y2i = map(int, [x1, y1, x2, y2])\n",
    "            color = (255, 0, 0) if tid == 1 else (0, 255, 0)\n",
    "            cv2.rectangle(frame, (x1i, y1i), (x2i, y2i), color, 2)\n",
    "            cv2.putText(frame, f'ID {tid}', (x1i, y1i - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "            csv_writer.writerow([frame_idx, tid, x1, y1, x2, y2])\n",
    "\n",
    "        out.write(frame)\n",
    "        frame_idx += 1\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    csv_file.close()\n",
    "    print(f\"✓ Finished: {video_path}\")\n",
    "\n",
    "#Batch runner \n",
    "def main():\n",
    "    video_dir = r\"D:\\DeepSORT_ML2025\\video_stitch\\cam15\"  # <-- replace with your video path\n",
    "    guide_root_dir = r\"D:\\DeepSORT_ML2025\\video_stitch\\cam10_cam11_tracked\"  # <-- base folder with guide subfolders\n",
    "    output_dir = r\"D:\\DeepSORT_ML2025\\video_stitch\\cam15_tracked\" \n",
    "    model_path = r\"D:\\DeepSORT_ML2025\\yolo_project\\marmoset_yolo_20250708_105031\\weights\\best.pt\"  # <-- replace\n",
    "\n",
    "    model = YOLO(model_path)\n",
    "\n",
    "    for fname in os.listdir(video_dir):\n",
    "        if not fname.endswith(\".mp4\"):\n",
    "            continue\n",
    "        if \"cam15\" not in fname and \"cam18\" not in fname:\n",
    "            continue\n",
    "\n",
    "        full_path = os.path.join(video_dir, fname)\n",
    "        base_name = fname.replace(\"_cam15_\", \"\").replace(\"_cam18_\", \"\").replace(\"__\", \"_\").replace(\"--\", \"-\")\n",
    "        base_name = os.path.splitext(base_name)[0]\n",
    "\n",
    "        guide_path = os.path.join(guide_root_dir, base_name, f\"{base_name}_id1_x2_position_corrected.txt\")\n",
    "        if not os.path.exists(guide_path):\n",
    "            print(f\"⚠️ Guide not found: {guide_path}\")\n",
    "            continue\n",
    "\n",
    "                        # Remove common suffix patterns like _from_18_pre or _from_18_post\n",
    "        clean_base_name = base_name.split(\"_from_\")[0]\n",
    "        video_output_dir = os.path.join(output_dir, clean_base_name)\n",
    "\n",
    "        track_video(full_path, guide_path, video_output_dir, model)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f70146a",
   "metadata": {},
   "source": [
    "### Some transforms due to stitching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d816f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Corrected: D:\\DeepSORT_ML2025\\video_stitch\\cam10_cam11_tracked\\JM_ind1post\\JM_ind1post_cam11.csv\n",
      "✔ Corrected: D:\\DeepSORT_ML2025\\video_stitch\\cam10_cam11_tracked\\JM_ind1pre\\JM_ind1pre_cam11.csv\n",
      "✔ Corrected: D:\\DeepSORT_ML2025\\video_stitch\\cam10_cam11_tracked\\JM_ind2post\\JM_ind2post_cam11.csv\n",
      "✔ Corrected: D:\\DeepSORT_ML2025\\video_stitch\\cam10_cam11_tracked\\JM_ind2pre\\JM_ind2pre_cam11.csv\n",
      "✔ Corrected: D:\\DeepSORT_ML2025\\video_stitch\\cam10_cam11_tracked\\JM_ind4post\\JM_ind4post_cam11.csv\n",
      "✔ Corrected: D:\\DeepSORT_ML2025\\video_stitch\\cam10_cam11_tracked\\JM_ind4pre\\JM_ind4pre_cam11.csv\n",
      "✔ Corrected: D:\\DeepSORT_ML2025\\video_stitch\\cam10_cam11_tracked\\JM_pro1post\\JM_pro1post_cam11.csv\n",
      "✔ Corrected: D:\\DeepSORT_ML2025\\video_stitch\\cam10_cam11_tracked\\JM_pro1pre\\JM_pro1pre_cam11.csv\n",
      "✔ Corrected: D:\\DeepSORT_ML2025\\video_stitch\\cam10_cam11_tracked\\JM_pro2post\\JM_pro2post_cam11.csv\n",
      "✔ Corrected: D:\\DeepSORT_ML2025\\video_stitch\\cam10_cam11_tracked\\JM_pro2pre\\JM_pro2pre_cam11.csv\n",
      "✔ Corrected: D:\\DeepSORT_ML2025\\video_stitch\\cam10_cam11_tracked\\JM_pro4post\\JM_pro4post_cam11.csv\n",
      "✔ Corrected: D:\\DeepSORT_ML2025\\video_stitch\\cam10_cam11_tracked\\JM_pro4pre\\JM_pro4pre_cam11.csv\n",
      "✔ Corrected: D:\\DeepSORT_ML2025\\video_stitch\\cam10_cam11_tracked\\JM_rew2post\\JM_rew2post_cam11.csv\n",
      "✔ Corrected: D:\\DeepSORT_ML2025\\video_stitch\\cam10_cam11_tracked\\JM_rew2pre\\JM_rew2pre_cam11.csv\n",
      "✔ Corrected: D:\\DeepSORT_ML2025\\video_stitch\\cam10_cam11_tracked\\JM_rew3post\\JM_rew3post_cam11.csv\n",
      "✔ Corrected: D:\\DeepSORT_ML2025\\video_stitch\\cam10_cam11_tracked\\JM_rew3pre\\JM_rew3pre_cam11.csv\n",
      "✔ Corrected: D:\\DeepSORT_ML2025\\video_stitch\\cam10_cam11_tracked\\JM_rew4post\\JM_rew4post_cam11.csv\n",
      "✔ Corrected: D:\\DeepSORT_ML2025\\video_stitch\\cam10_cam11_tracked\\JM_rew4pre\\JM_rew4pre_cam11.csv\n",
      "✔ Corrected: D:\\DeepSORT_ML2025\\video_stitch\\cam10_cam11_tracked\\LL_ind1post\\LL_ind1post_cam11.csv\n",
      "✔ Corrected: D:\\DeepSORT_ML2025\\video_stitch\\cam10_cam11_tracked\\LL_ind1pre\\LL_ind1pre_cam11.csv\n",
      "✔ Corrected: D:\\DeepSORT_ML2025\\video_stitch\\cam10_cam11_tracked\\LL_ind2post\\LL_ind2post_cam11.csv\n",
      "✔ Corrected: D:\\DeepSORT_ML2025\\video_stitch\\cam10_cam11_tracked\\LL_ind2pre\\LL_ind2pre_cam11.csv\n",
      "✔ Corrected: D:\\DeepSORT_ML2025\\video_stitch\\cam10_cam11_tracked\\LL_ind3post\\LL_ind3post_cam11.csv\n",
      "✔ Corrected: D:\\DeepSORT_ML2025\\video_stitch\\cam10_cam11_tracked\\LL_ind3pre\\LL_ind3pre_cam11.csv\n",
      "✔ Corrected: D:\\DeepSORT_ML2025\\video_stitch\\cam10_cam11_tracked\\LL_pro2post\\LL_pro2post_cam11.csv\n",
      "✔ Corrected: D:\\DeepSORT_ML2025\\video_stitch\\cam10_cam11_tracked\\LL_pro2pre\\LL_pro2pre_cam11.csv\n",
      "✔ Corrected: D:\\DeepSORT_ML2025\\video_stitch\\cam10_cam11_tracked\\LL_pro4post\\LL_pro4post_cam11.csv\n",
      "✔ Corrected: D:\\DeepSORT_ML2025\\video_stitch\\cam10_cam11_tracked\\LL_pro4pre\\LL_pro4pre_cam11.csv\n",
      "✔ Corrected: D:\\DeepSORT_ML2025\\video_stitch\\cam10_cam11_tracked\\LL_pro5post\\LL_pro5post_cam11.csv\n",
      "✔ Corrected: D:\\DeepSORT_ML2025\\video_stitch\\cam10_cam11_tracked\\LL_pro5pre\\LL_pro5pre_cam11.csv\n",
      "✔ Corrected: D:\\DeepSORT_ML2025\\video_stitch\\cam10_cam11_tracked\\LL_rew1post\\LL_rew1post_cam11.csv\n",
      "✔ Corrected: D:\\DeepSORT_ML2025\\video_stitch\\cam10_cam11_tracked\\LL_rew1pre\\LL_rew1pre_cam11.csv\n",
      "✔ Corrected: D:\\DeepSORT_ML2025\\video_stitch\\cam10_cam11_tracked\\LL_rew2post\\LL_rew2post_cam11.csv\n",
      "✔ Corrected: D:\\DeepSORT_ML2025\\video_stitch\\cam10_cam11_tracked\\LL_rew2pre\\LL_rew2pre_cam11.csv\n",
      "✔ Corrected: D:\\DeepSORT_ML2025\\video_stitch\\cam10_cam11_tracked\\LL_rew3post\\LL_rew3post_cam11.csv\n",
      "✔ Corrected: D:\\DeepSORT_ML2025\\video_stitch\\cam10_cam11_tracked\\LL_rew3pre\\LL_rew3pre_cam11.csv\n",
      "✔ Corrected: D:\\DeepSORT_ML2025\\video_stitch\\cam10_cam11_tracked\\NuNo_ind1post\\NuNo_ind1post_cam11.csv\n",
      "✔ Corrected: D:\\DeepSORT_ML2025\\video_stitch\\cam10_cam11_tracked\\NuNo_ind1pre\\NuNo_ind1pre_cam11.csv\n",
      "✔ Corrected: D:\\DeepSORT_ML2025\\video_stitch\\cam10_cam11_tracked\\NuNo_ind2post\\NuNo_ind2post_cam11.csv\n",
      "✔ Corrected: D:\\DeepSORT_ML2025\\video_stitch\\cam10_cam11_tracked\\NuNo_ind2pre\\NuNo_ind2pre_cam11.csv\n",
      "✔ Corrected: D:\\DeepSORT_ML2025\\video_stitch\\cam10_cam11_tracked\\NuNo_ind3post\\NuNo_ind3post_cam11.csv\n",
      "✔ Corrected: D:\\DeepSORT_ML2025\\video_stitch\\cam10_cam11_tracked\\NuNo_ind3pre\\NuNo_ind3pre_cam11.csv\n",
      "✔ Corrected: D:\\DeepSORT_ML2025\\video_stitch\\cam10_cam11_tracked\\NuNo_pro1post\\NuNo_pro1post_cam11.csv\n",
      "✔ Corrected: D:\\DeepSORT_ML2025\\video_stitch\\cam10_cam11_tracked\\NuNo_pro1pre\\NuNo_pro1pre_cam11.csv\n",
      "✔ Corrected: D:\\DeepSORT_ML2025\\video_stitch\\cam10_cam11_tracked\\NuNo_pro2post\\NuNo_pro2post_cam11.csv\n",
      "✔ Corrected: D:\\DeepSORT_ML2025\\video_stitch\\cam10_cam11_tracked\\NuNo_pro2pre\\NuNo_pro2pre_cam11.csv\n",
      "✔ Corrected: D:\\DeepSORT_ML2025\\video_stitch\\cam10_cam11_tracked\\NuNo_pro3post\\NuNo_pro3post_cam11.csv\n",
      "✔ Corrected: D:\\DeepSORT_ML2025\\video_stitch\\cam10_cam11_tracked\\NuNo_pro3pre\\NuNo_pro3pre_cam11.csv\n",
      "✔ Corrected: D:\\DeepSORT_ML2025\\video_stitch\\cam10_cam11_tracked\\NuNo_rew1post\\NuNo_rew1post_cam11.csv\n",
      "✔ Corrected: D:\\DeepSORT_ML2025\\video_stitch\\cam10_cam11_tracked\\NuNo_rew1pre\\NuNo_rew1pre_cam11.csv\n",
      "✔ Corrected: D:\\DeepSORT_ML2025\\video_stitch\\cam10_cam11_tracked\\NuNo_rew2post\\NuNo_rew2post_cam11.csv\n",
      "✔ Corrected: D:\\DeepSORT_ML2025\\video_stitch\\cam10_cam11_tracked\\NuNo_rew2pre\\NuNo_rew2pre_cam11.csv\n",
      "✔ Corrected: D:\\DeepSORT_ML2025\\video_stitch\\cam10_cam11_tracked\\NuNo_rew3post\\NuNo_rew3post_cam11.csv\n",
      "✔ Corrected: D:\\DeepSORT_ML2025\\video_stitch\\cam10_cam11_tracked\\NuNo_rew3pre\\NuNo_rew3pre_cam11.csv\n",
      "✔ Corrected: D:\\DeepSORT_ML2025\\video_stitch\\cam10_cam11_tracked\\NuNy_ind1post\\NuNy_ind1post_cam11.csv\n",
      "✔ Corrected: D:\\DeepSORT_ML2025\\video_stitch\\cam10_cam11_tracked\\NuNy_ind1pre\\NuNy_ind1pre_cam11.csv\n",
      "✔ Corrected: D:\\DeepSORT_ML2025\\video_stitch\\cam10_cam11_tracked\\NuNy_ind2post\\NuNy_ind2post_cam11.csv\n",
      "✔ Corrected: D:\\DeepSORT_ML2025\\video_stitch\\cam10_cam11_tracked\\NuNy_ind2pre\\NuNy_ind2pre_cam11.csv\n",
      "✔ Corrected: D:\\DeepSORT_ML2025\\video_stitch\\cam10_cam11_tracked\\NuNy_ind3post\\NuNy_ind3post_cam11.csv\n",
      "✔ Corrected: D:\\DeepSORT_ML2025\\video_stitch\\cam10_cam11_tracked\\NuNy_ind3pre\\NuNy_ind3pre_cam11.csv\n",
      "✔ Corrected: D:\\DeepSORT_ML2025\\video_stitch\\cam10_cam11_tracked\\NuNy_pro1post\\NuNy_pro1post_cam11.csv\n",
      "✔ Corrected: D:\\DeepSORT_ML2025\\video_stitch\\cam10_cam11_tracked\\NuNy_pro1pre\\NuNy_pro1pre_cam11.csv\n",
      "✔ Corrected: D:\\DeepSORT_ML2025\\video_stitch\\cam10_cam11_tracked\\NuNy_pro2post\\NuNy_pro2post_cam11.csv\n",
      "✔ Corrected: D:\\DeepSORT_ML2025\\video_stitch\\cam10_cam11_tracked\\NuNy_pro2pre\\NuNy_pro2pre_cam11.csv\n",
      "✔ Corrected: D:\\DeepSORT_ML2025\\video_stitch\\cam10_cam11_tracked\\NuNy_pro3post\\NuNy_pro3post_cam11.csv\n",
      "✔ Corrected: D:\\DeepSORT_ML2025\\video_stitch\\cam10_cam11_tracked\\NuNy_pro3pre\\NuNy_pro3pre_cam11.csv\n",
      "✔ Corrected: D:\\DeepSORT_ML2025\\video_stitch\\cam10_cam11_tracked\\NuNy_rew2post\\NuNy_rew2post_cam11.csv\n",
      "✔ Corrected: D:\\DeepSORT_ML2025\\video_stitch\\cam10_cam11_tracked\\NuNy_rew2pre\\NuNy_rew2pre_cam11.csv\n",
      "✔ Corrected: D:\\DeepSORT_ML2025\\video_stitch\\cam10_cam11_tracked\\NuNy_rew3post\\NuNy_rew3post_cam11.csv\n",
      "✔ Corrected: D:\\DeepSORT_ML2025\\video_stitch\\cam10_cam11_tracked\\NuNy_rew3pre\\NuNy_rew3pre_cam11.csv\n",
      "✔ Corrected: D:\\DeepSORT_ML2025\\video_stitch\\cam10_cam11_tracked\\NuNy_rew4post\\NuNy_rew4post_cam11.csv\n",
      "✔ Corrected: D:\\DeepSORT_ML2025\\video_stitch\\cam10_cam11_tracked\\NuNy_rew4pre\\NuNy_rew4pre_cam11.csv\n",
      "✔ Corrected: D:\\DeepSORT_ML2025\\video_stitch\\cam10_cam11_tracked\\NyNo_ind1post\\NyNo_ind1post_cam11.csv\n",
      "✔ Corrected: D:\\DeepSORT_ML2025\\video_stitch\\cam10_cam11_tracked\\NyNo_ind1pre\\NyNo_ind1pre_cam11.csv\n",
      "✔ Corrected: D:\\DeepSORT_ML2025\\video_stitch\\cam10_cam11_tracked\\NyNo_ind2post\\NyNo_ind2post_cam11.csv\n",
      "✔ Corrected: D:\\DeepSORT_ML2025\\video_stitch\\cam10_cam11_tracked\\NyNo_ind2pre\\NyNo_ind2pre_cam11.csv\n",
      "✔ Corrected: D:\\DeepSORT_ML2025\\video_stitch\\cam10_cam11_tracked\\NyNo_ind3post\\NyNo_ind3post_cam11.csv\n",
      "✔ Corrected: D:\\DeepSORT_ML2025\\video_stitch\\cam10_cam11_tracked\\NyNo_ind3pre\\NyNo_ind3pre_cam11.csv\n",
      "✔ Corrected: D:\\DeepSORT_ML2025\\video_stitch\\cam10_cam11_tracked\\NyNo_pro1post\\NyNo_pro1post_cam11.csv\n",
      "✔ Corrected: D:\\DeepSORT_ML2025\\video_stitch\\cam10_cam11_tracked\\NyNo_pro1pre\\NyNo_pro1pre_cam11.csv\n",
      "✔ Corrected: D:\\DeepSORT_ML2025\\video_stitch\\cam10_cam11_tracked\\NyNo_pro2post\\NyNo_pro2post_cam11.csv\n",
      "✔ Corrected: D:\\DeepSORT_ML2025\\video_stitch\\cam10_cam11_tracked\\NyNo_pro2pre\\NyNo_pro2pre_cam11.csv\n",
      "✔ Corrected: D:\\DeepSORT_ML2025\\video_stitch\\cam10_cam11_tracked\\NyNo_pro3post\\NyNo_pro3post_cam11.csv\n",
      "✔ Corrected: D:\\DeepSORT_ML2025\\video_stitch\\cam10_cam11_tracked\\NyNo_pro3pre\\NyNo_pro3pre_cam11.csv\n",
      "✔ Corrected: D:\\DeepSORT_ML2025\\video_stitch\\cam10_cam11_tracked\\NyNo_rew1post\\NyNo_rew1post_cam11.csv\n",
      "✔ Corrected: D:\\DeepSORT_ML2025\\video_stitch\\cam10_cam11_tracked\\NyNo_rew1pre\\NyNo_rew1pre_cam11.csv\n",
      "✔ Corrected: D:\\DeepSORT_ML2025\\video_stitch\\cam10_cam11_tracked\\NyNo_rew2post\\NyNo_rew2post_cam11.csv\n",
      "✔ Corrected: D:\\DeepSORT_ML2025\\video_stitch\\cam10_cam11_tracked\\NyNo_rew2pre\\NyNo_rew2pre_cam11.csv\n",
      "✔ Corrected: D:\\DeepSORT_ML2025\\video_stitch\\cam10_cam11_tracked\\NyNo_rew4post\\NyNo_rew4post_cam11.csv\n",
      "✔ Corrected: D:\\DeepSORT_ML2025\\video_stitch\\cam10_cam11_tracked\\NyNo_rew4pre\\NyNo_rew4pre_cam11.csv\n",
      "✔ Corrected: D:\\DeepSORT_ML2025\\video_stitch\\cam10_cam11_tracked\\VV_ind1post\\VV_ind1post_cam11.csv\n",
      "✔ Corrected: D:\\DeepSORT_ML2025\\video_stitch\\cam10_cam11_tracked\\VV_ind1pre\\VV_ind1pre_cam11.csv\n",
      "✔ Corrected: D:\\DeepSORT_ML2025\\video_stitch\\cam10_cam11_tracked\\VV_ind2post\\VV_ind2post_cam11.csv\n",
      "✔ Corrected: D:\\DeepSORT_ML2025\\video_stitch\\cam10_cam11_tracked\\VV_ind2pre\\VV_ind2pre_cam11.csv\n",
      "✔ Corrected: D:\\DeepSORT_ML2025\\video_stitch\\cam10_cam11_tracked\\VV_ind4post\\VV_ind4post_cam11.csv\n",
      "✔ Corrected: D:\\DeepSORT_ML2025\\video_stitch\\cam10_cam11_tracked\\VV_ind4pre\\VV_ind4pre_cam11.csv\n",
      "✔ Corrected: D:\\DeepSORT_ML2025\\video_stitch\\cam10_cam11_tracked\\VV_pro1post\\VV_pro1post_cam11.csv\n",
      "✔ Corrected: D:\\DeepSORT_ML2025\\video_stitch\\cam10_cam11_tracked\\VV_pro1pre\\VV_pro1pre_cam11.csv\n",
      "✔ Corrected: D:\\DeepSORT_ML2025\\video_stitch\\cam10_cam11_tracked\\VV_pro2post\\VV_pro2post_cam11.csv\n",
      "✔ Corrected: D:\\DeepSORT_ML2025\\video_stitch\\cam10_cam11_tracked\\VV_pro2pre\\VV_pro2pre_cam11.csv\n",
      "✔ Corrected: D:\\DeepSORT_ML2025\\video_stitch\\cam10_cam11_tracked\\VV_pro3post\\VV_pro3post_cam11.csv\n",
      "✔ Corrected: D:\\DeepSORT_ML2025\\video_stitch\\cam10_cam11_tracked\\VV_pro3pre\\VV_pro3pre_cam11.csv\n",
      "✔ Corrected: D:\\DeepSORT_ML2025\\video_stitch\\cam10_cam11_tracked\\VV_rew1post\\VV_rew1post_cam11.csv\n",
      "✔ Corrected: D:\\DeepSORT_ML2025\\video_stitch\\cam10_cam11_tracked\\VV_rew1pre\\VV_rew1pre_cam11.csv\n",
      "✔ Corrected: D:\\DeepSORT_ML2025\\video_stitch\\cam10_cam11_tracked\\VV_rew3post\\VV_rew3post_cam11.csv\n",
      "✔ Corrected: D:\\DeepSORT_ML2025\\video_stitch\\cam10_cam11_tracked\\VV_rew3pre\\VV_rew3pre_cam11.csv\n",
      "✔ Corrected: D:\\DeepSORT_ML2025\\video_stitch\\cam10_cam11_tracked\\VV_rew4post\\VV_rew4post_cam11.csv\n",
      "✔ Corrected: D:\\DeepSORT_ML2025\\video_stitch\\cam10_cam11_tracked\\VV_rew4pre\\VV_rew4pre_cam11.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "root_dir = r\"D:\\DeepSORT_ML2025\\video_stitch\\cam10_cam11_tracked\"  # CHANGE this to your root folder\n",
    "H, W = 1080, 1920  # Video height and width\n",
    "\n",
    "\n",
    "inverse_transform_matrix = np.array([\n",
    "    [ 1.05403131,  0.12941877, -51.0827529],\n",
    "    [-0.14624321,  1.19105538, 136.228942],\n",
    "    [ 0.0,         0.0,          1.0     ]\n",
    "])\n",
    "\n",
    "\n",
    "def get_correct_transform_matrix(shape):\n",
    "    H, W = shape\n",
    "    src_pts = np.float32([[W//2, 0], [W-1, 0], [W//2, H-1]])\n",
    "    dst_pts = np.float32([[W//2 + 30, 5], [W + 45, 0], [W//2 + 45, H]])\n",
    "    matrix = cv2.getAffineTransform(src_pts, dst_pts)\n",
    "    return matrix\n",
    "\n",
    "correct_transform_matrix = get_correct_transform_matrix((H, W))\n",
    "\n",
    "\n",
    "def apply_combined_transform(x1, y1, x2, y2):\n",
    "    def apply(M, x, y):\n",
    "        pt = np.array([x, y, 1.0])\n",
    "        out = M @ pt\n",
    "        return out[0], out[1]\n",
    "\n",
    "    # Undo previous inverse transform\n",
    "    x1u, y1u = apply(np.linalg.inv(inverse_transform_matrix), x1, y1)\n",
    "    x2u, y2u = apply(np.linalg.inv(inverse_transform_matrix), x2, y2)\n",
    "\n",
    "    # Apply correct transform\n",
    "    x1c, y1c = apply(correct_transform_matrix, x1u, y1u)\n",
    "    x2c, y2c = apply(correct_transform_matrix, x2u, y2u)\n",
    "\n",
    "    return [x1c, y1c, x2c, y2c]\n",
    "\n",
    "\n",
    "def correct_csv(filepath):\n",
    "    try:\n",
    "        df = pd.read_csv(filepath)\n",
    "        if not {'x1', 'y1', 'x2', 'y2'}.issubset(df.columns):\n",
    "            print(f\"Skipping {filepath} — missing box columns.\")\n",
    "            return\n",
    "        corrected = []\n",
    "        for _, row in df.iterrows():\n",
    "            if pd.isna(row['x1']) or pd.isna(row['y1']) or pd.isna(row['x2']) or pd.isna(row['y2']):\n",
    "                corrected.append([np.nan]*4)\n",
    "            else:\n",
    "                corrected.append(apply_combined_transform(row['x1'], row['y1'], row['x2'], row['y2']))\n",
    "        corrected = np.array(corrected)\n",
    "        df[['x1', 'y1', 'x2', 'y2']] = corrected\n",
    "        df.to_csv(filepath, index=False)\n",
    "        print(f\"✔ Corrected: {filepath}\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error in {filepath}: {e}\")\n",
    "\n",
    "\n",
    "for dirpath, _, filenames in os.walk(root_dir):\n",
    "    for filename in filenames:\n",
    "        if filename.endswith(\"cam11.csv\"):\n",
    "            csv_path = os.path.join(dirpath, filename)\n",
    "            correct_csv(csv_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7988d5e4",
   "metadata": {},
   "source": [
    "### Masking Videos for DLC with padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcae850",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "def draw_masked_boxes(video_path, csv_path, output_path_prefix, wiggle=7):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Cannot open video: {video_path}\")\n",
    "        return\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "    bboxes_by_frame_id = {}\n",
    "    with open(csv_path, 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        header = next(reader)\n",
    "        if all(x in header for x in ['x1', 'y1', 'x2', 'y2']):\n",
    "            idx_frame = header.index('frame')\n",
    "            idx_id = header.index('id')\n",
    "            idx_x1 = header.index('x1')\n",
    "            idx_y1 = header.index('y1')\n",
    "            idx_x2 = header.index('x2')\n",
    "            idx_y2 = header.index('y2')\n",
    "            for row in reader:\n",
    "                if row[idx_x1] == '' or row[idx_y1] == '' or row[idx_x2] == '' or row[idx_y2] == '':\n",
    "                    continue\n",
    "                frame_i = int(row[idx_frame])\n",
    "                id_i = int(row[idx_id])\n",
    "                x1 = int(float(row[idx_x1])) - wiggle\n",
    "                y1 = int(float(row[idx_y1])) - wiggle\n",
    "                x2 = int(float(row[idx_x2])) + wiggle\n",
    "                y2 = int(float(row[idx_y2])) + wiggle\n",
    "                bboxes_by_frame_id.setdefault(frame_i, {}).setdefault(id_i, []).append([\n",
    "                    max(0, x1), max(0, y1), min(width - 1, x2), min(height - 1, y2)\n",
    "                ])\n",
    "        else:\n",
    "            idx_frame = header.index('frame')\n",
    "            idx_id = header.index('id')\n",
    "            idx_cx = header.index('cx')\n",
    "            idx_cy = header.index('cy')\n",
    "            bbox_w = 50 + 2 * wiggle\n",
    "            bbox_h = 50 + 2 * wiggle\n",
    "            for row in reader:\n",
    "                if row[idx_cx] == '' or row[idx_cy] == '':\n",
    "                    continue\n",
    "                frame_i = int(row[idx_frame])\n",
    "                id_i = int(row[idx_id])\n",
    "                cx = float(row[idx_cx])\n",
    "                cy = float(row[idx_cy])\n",
    "                x1 = int(cx - bbox_w // 2)\n",
    "                y1 = int(cy - bbox_h // 2)\n",
    "                x2 = int(cx + bbox_w // 2)\n",
    "                y2 = int(cy + bbox_h // 2)\n",
    "                bboxes_by_frame_id.setdefault(frame_i, {}).setdefault(id_i, []).append([\n",
    "                    max(0, x1), max(0, y1), min(width - 1, x2), min(height - 1, y2)\n",
    "                ])\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out1 = cv2.VideoWriter(f'{output_path_prefix}_ID1.mp4', fourcc, fps, (width, height))\n",
    "    out2 = cv2.VideoWriter(f'{output_path_prefix}_ID2.mp4', fourcc, fps, (width, height))\n",
    "\n",
    "    frame_idx = 0\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        white_bg = np.ones_like(frame, dtype=np.uint8) * 255\n",
    "        for bbox in bboxes_by_frame_id.get(frame_idx, {}).get(1, []):\n",
    "            x1, y1, x2, y2 = bbox\n",
    "            white_bg[y1:y2, x1:x2] = frame[y1:y2, x1:x2]\n",
    "        out1.write(white_bg)\n",
    "\n",
    "        white_bg = np.ones_like(frame, dtype=np.uint8) * 255\n",
    "        for bbox in bboxes_by_frame_id.get(frame_idx, {}).get(2, []):\n",
    "            x1, y1, x2, y2 = bbox\n",
    "            white_bg[y1:y2, x1:x2] = frame[y1:y2, x1:x2]\n",
    "        out2.write(white_bg)\n",
    "\n",
    "        frame_idx += 1\n",
    "\n",
    "    cap.release()\n",
    "    out1.release()\n",
    "    out2.release()\n",
    "    print(f\"Finished masked videos for {os.path.basename(video_path)}\")\n",
    "\n",
    "def video_name_to_csv_folder_cam15_18(video_name, cam_num):\n",
    "    if cam_num == 15:\n",
    "        base = video_name.replace('_cam15_', '_')\n",
    "    elif cam_num == 18:\n",
    "        base = video_name.replace('_cam18_', '_')\n",
    "    else:\n",
    "        base = video_name\n",
    "\n",
    "    if base.endswith('_pre'):\n",
    "        suffix = 'pre'\n",
    "        base = base[:-4] + 'pre'\n",
    "    elif base.endswith('_post'):\n",
    "        suffix = 'post'\n",
    "        base = base[:-5] + 'post'\n",
    "    else:\n",
    "        suffix = ''\n",
    "\n",
    "    return f\"{base}_from_{cam_num}_{suffix}\"\n",
    "\n",
    "def find_csv_folder_for_cam15_18(csv_root, video_name_wo_ext, cam_num):\n",
    "    target_folder = video_name_to_csv_folder_cam15_18(video_name_wo_ext, cam_num)\n",
    "    full_path = os.path.join(csv_root, target_folder)\n",
    "    return full_path if os.path.exists(full_path) else None\n",
    "\n",
    "def process_cam15_or_18(cam_dir, csv_root, output_root, cam_num):\n",
    "    for video_filename in os.listdir(cam_dir):\n",
    "        if not video_filename.endswith('.mp4'):\n",
    "            continue\n",
    "        name_wo_ext = os.path.splitext(video_filename)[0]\n",
    "        video_path = os.path.join(cam_dir, video_filename)\n",
    "\n",
    "        csv_folder = find_csv_folder_for_cam15_18(csv_root, name_wo_ext, cam_num)\n",
    "        if csv_folder is None:\n",
    "            print(f\"No CSV folder found for {name_wo_ext} in {csv_root} for cam{cam_num}\")\n",
    "            continue\n",
    "\n",
    "        csv_path = os.path.join(csv_folder, f\"{name_wo_ext}_tracking.csv\")\n",
    "        out_folder = os.path.join(output_root, f\"cam{cam_num}\", os.path.basename(csv_folder))\n",
    "        os.makedirs(out_folder, exist_ok=True)\n",
    "\n",
    "        if os.path.exists(video_path) and os.path.exists(csv_path):\n",
    "            print(f\"Processing cam{cam_num} video: {video_path}\")\n",
    "            draw_masked_boxes(video_path, csv_path, os.path.join(out_folder, os.path.basename(csv_folder)))\n",
    "        else:\n",
    "            print(f\"Missing cam{cam_num} video or CSV for {os.path.basename(csv_folder)}\")\n",
    "            print(f\"  Expected video: {video_path}\")\n",
    "            print(f\"  Expected CSV:   {csv_path}\")\n",
    "\n",
    "def main():\n",
    "    root_videos = r\"D:\\DeepSORT_ML2025\\video_stitch\"\n",
    "    cam15_csv_root = r\"D:\\cam15_tracked_with_guide\"\n",
    "    cam18_csv_root = r\"D:\\cam18_tracked_with_guide\"\n",
    "    output_root = r\"D:\\MaskedVideos_PerID_padded\"\n",
    "\n",
    "    print(\"Processing cam15...\")\n",
    "    process_cam15_or_18(os.path.join(root_videos, 'cam15'), cam15_csv_root, output_root, cam_num=15)\n",
    "\n",
    "    print(\"Processing cam18...\")\n",
    "    process_cam15_or_18(os.path.join(root_videos, 'cam18'), cam18_csv_root, output_root, cam_num=18)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0c6f07",
   "metadata": {},
   "source": [
    "### Cubic Spline on centres of BBoxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f35af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.interpolate import CubicSpline\n",
    "\n",
    "def interpolate_centers(csv_path, output_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    required_cols = ['frame', 'id', 'x1', 'y1', 'x2', 'y2']\n",
    "    for c in required_cols:\n",
    "        if c not in df.columns:\n",
    "            print(f\"Skipping {csv_path} - missing column {c}\")\n",
    "            return\n",
    "\n",
    "    df['cx'] = (df['x1'] + df['x2']) / 2\n",
    "    df['cy'] = (df['y1'] + df['y2']) / 2\n",
    "\n",
    "    unique_ids = df['id'].unique()\n",
    "\n",
    "    if len(unique_ids) == 1:\n",
    "        print(f\"Only one ID in {csv_path}, skipping interpolation.\")\n",
    "        result_df = df[['frame', 'id', 'cx', 'cy']].copy()\n",
    "        os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "        result_df.to_csv(output_path, index=False)\n",
    "        print(f\"Saved center coordinates (no interpolation) to {output_path}\")\n",
    "        return\n",
    "\n",
    "    interpolated_rows = []\n",
    "    for obj_id, group in df.groupby('id'):\n",
    "        group = group.sort_values('frame')\n",
    "\n",
    "        frames = group['frame'].values\n",
    "        cx_vals = group['cx'].values\n",
    "        cy_vals = group['cy'].values\n",
    "\n",
    "        valid_mask = np.isfinite(cx_vals) & np.isfinite(cy_vals) & np.isfinite(frames)\n",
    "        frames_valid = frames[valid_mask]\n",
    "        cx_valid = cx_vals[valid_mask]\n",
    "        cy_valid = cy_vals[valid_mask]\n",
    "\n",
    "        if len(frames_valid) < 4:\n",
    "            interpolated_rows.append(group[['frame', 'id', 'cx', 'cy']])\n",
    "            continue\n",
    "\n",
    "        full_frames = np.arange(frames_valid.min(), frames_valid.max() + 1)\n",
    "\n",
    "        cs_x = CubicSpline(frames_valid, cx_valid, bc_type='natural')\n",
    "        cs_y = CubicSpline(frames_valid, cy_valid, bc_type='natural')\n",
    "\n",
    "        interp_cx = cs_x(full_frames)\n",
    "        interp_cy = cs_y(full_frames)\n",
    "\n",
    "        interp_df = pd.DataFrame({\n",
    "            'frame': full_frames,\n",
    "            'id': obj_id,\n",
    "            'cx': interp_cx,\n",
    "            'cy': interp_cy\n",
    "        })\n",
    "\n",
    "        interpolated_rows.append(interp_df)\n",
    "\n",
    "    result_df = pd.concat(interpolated_rows, ignore_index=True)\n",
    "    result_df = result_df.sort_values(['frame', 'id'])\n",
    "\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    result_df.to_csv(output_path, index=False)\n",
    "    print(f\"Saved interpolated centers to {output_path}\")\n",
    "\n",
    "def process_corrected_folder(corrected_folder_path):\n",
    "    print(f\"Processing folder: {corrected_folder_path}\")\n",
    "\n",
    "    # Determine parent directory and corrected_interpolated folder path\n",
    "    parent_dir = os.path.dirname(corrected_folder_path)\n",
    "    corrected_interpolated_folder = os.path.join(parent_dir, 'corrected_interpolated')\n",
    "\n",
    "    # Create corrected_interpolated folder if it doesn't exist\n",
    "    os.makedirs(corrected_interpolated_folder, exist_ok=True)\n",
    "\n",
    "    # Process all CSV files inside corrected folder\n",
    "    for fname in os.listdir(corrected_folder_path):\n",
    "        if fname.lower().endswith('.csv'):\n",
    "            input_csv = os.path.join(corrected_folder_path, fname)\n",
    "            base_name = os.path.splitext(fname)[0]\n",
    "            output_fname = f\"{base_name}_centre_interpol.csv\"\n",
    "            output_csv = os.path.join(corrected_interpolated_folder, output_fname)\n",
    "\n",
    "            interpolate_centers(input_csv, output_csv)\n",
    "\n",
    "def walk_and_process(root_dir):\n",
    "    # Walk recursively and look for 'corrected' folders\n",
    "    for dirpath, dirnames, filenames in os.walk(root_dir):\n",
    "        # Copy dirnames because we'll modify it in-place\n",
    "        for dirname in dirnames:\n",
    "            if dirname.lower() == 'corrected':\n",
    "                corrected_path = os.path.join(dirpath, dirname)\n",
    "                process_corrected_folder(corrected_path)\n",
    "\n",
    "def main():\n",
    "    root_dir = r\"D:\\DeepSORT_ML2025\\video_stitch\\sorted_csv\"\n",
    "    if not os.path.isdir(root_dir):\n",
    "        print(f\"Error: The path '{root_dir}' is not a valid directory.\")\n",
    "        return\n",
    "    walk_and_process(root_dir)\n",
    "    print(\"Processing complete.\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1d30ad",
   "metadata": {},
   "source": [
    "### Triangulation + Distance calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7996d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from filterpy.kalman import KalmanFilter\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "from scipy.interpolate import CubicSpline\n",
    "from scipy.signal import savgol_filter\n",
    "import scipy.stats\n",
    "\n",
    "# Intrinsic Matrices \n",
    "K_cam10 = np.array([[2711.6, 19.5268, -68.165],\n",
    "                    [0, 2668.7, 158.146],\n",
    "                    [0, 0, 1]])\n",
    "\n",
    "K_cam11 = np.array([[2609.9, -18.9653, 799.908],\n",
    "                    [0, 2471.6, 420.996],\n",
    "                    [0, 0, 1]])\n",
    "\n",
    "K_cam18 = np.array([[3056.7, 83.7254, -718.479],\n",
    "                    [0, 2412.1, 307.2416],\n",
    "                    [0, 0, 1]])\n",
    "\n",
    "K_cam15 = np.array([[2809.8, -27.3469, 1163.2],\n",
    "                    [0, 2448.5, 364.079],\n",
    "                    [0, 0, 1]])\n",
    "\n",
    "#Extrinsics\n",
    "R_10_18 = np.array([\n",
    "    [0.0839, -0.0321, -0.5421],\n",
    "    [0.0013, 0.9984, -0.0571],\n",
    "    [0.5431, 0.0472, 0.8384]\n",
    "])\n",
    "T_10_18 = np.array([[1288.5], [-15.879], [148.983]])\n",
    "\n",
    "R_11_15 = np.array([\n",
    "    [0.8115, -0.2139, 0.5438],\n",
    "    [0.1884, 0.9767, 0.1030],\n",
    "    [-0.5531, 0.0189, 0.8329]\n",
    "])\n",
    "T_11_15 = np.array([[-1.143], [-119.637], [288.81]])\n",
    "\n",
    "MAX_DISTANCE_FROM_ORIGIN = 5000\n",
    "MAX_DEPTH = 10000\n",
    "\n",
    "def kalman_smooth(df):\n",
    "    smoothed = []\n",
    "    for (cam_id, obj_id), group in df.groupby(['camera', 'id']):\n",
    "        kf = KalmanFilter(dim_x=4, dim_z=2)\n",
    "        kf.F = np.array([[1, 0, 1, 0],\n",
    "                         [0, 1, 0, 1],\n",
    "                         [0, 0, 1, 0],\n",
    "                         [0, 0, 0, 1]])\n",
    "        kf.H = np.array([[1, 0, 0, 0],\n",
    "                         [0, 1, 0, 0]])\n",
    "        kf.P *= 10.\n",
    "        kf.R *= 1.\n",
    "        kf.Q *= 0.01\n",
    "\n",
    "        group = group.sort_values('frame')\n",
    "        first = True\n",
    "        for _, row in group.iterrows():\n",
    "            if first:\n",
    "                kf.x[:2] = np.array([[row['cx']], [row['cy']]])\n",
    "                first = False\n",
    "            kf.predict()\n",
    "            kf.update([row['cx'], row['cy']])\n",
    "            smoothed.append({**row.to_dict(), 'cx': kf.x[0, 0], 'cy': kf.x[1, 0]})\n",
    "    return pd.DataFrame(smoothed)\n",
    "\n",
    "def triangulate_with_reasons(df1, df2, K1, K2, R, T):\n",
    "    df1 = df1.drop(columns=['camera'], errors='ignore')\n",
    "    df2 = df2.drop(columns=['camera'], errors='ignore')\n",
    "    df1 = df1.rename(columns={'cx': 'cx1', 'cy': 'cy1'})\n",
    "    df2 = df2.rename(columns={'cx': 'cx2', 'cy': 'cy2'})\n",
    "    merged = pd.merge(df1, df2, on=['frame', 'id'])\n",
    "    P1 = K1 @ np.hstack((np.eye(3), np.zeros((3, 1))))\n",
    "    P2 = K2 @ np.hstack((R, T))\n",
    "\n",
    "    points_data = []\n",
    "    for frame, group in merged.groupby(\"frame\"):\n",
    "        ids_in_frame = group[\"id\"].unique()\n",
    "        for obj_id in ids_in_frame:\n",
    "            row = group[group[\"id\"] == obj_id].iloc[0]\n",
    "            pt1 = np.array([[row[\"cx1\"]], [row[\"cy1\"]]])\n",
    "            pt2 = np.array([[row[\"cx2\"]], [row[\"cy2\"]]])\n",
    "            point_4d = cv2.triangulatePoints(P1, P2, pt1, pt2)\n",
    "            point_3d = (point_4d / point_4d[3])[:3].flatten()\n",
    "\n",
    "            swapped = False\n",
    "            reason = \"Valid\"\n",
    "            if not np.isfinite(point_3d).all():\n",
    "                reason = \"NaN or infinite coordinate\"\n",
    "                if len(ids_in_frame) == 2:\n",
    "                    other_id = [i for i in ids_in_frame if i != obj_id][0]\n",
    "                    other_row = group[group[\"id\"] == other_id].iloc[0]\n",
    "                    point_4d_swap = cv2.triangulatePoints(\n",
    "                        P1, P2,\n",
    "                        np.array([[other_row[\"cx1\"]], [other_row[\"cy1\"]]]),\n",
    "                        np.array([[row[\"cx2\"]], [row[\"cy2\"]]])\n",
    "                    )\n",
    "                    point_3d_swap = (point_4d_swap / point_4d_swap[3])[:3].flatten()\n",
    "                    if np.isfinite(point_3d_swap).all() and np.all(np.abs(point_3d_swap) < MAX_DISTANCE_FROM_ORIGIN) and 0 <= point_3d_swap[2] <= MAX_DEPTH:\n",
    "                        swapped = True\n",
    "                        point_3d = point_3d_swap\n",
    "                        reason = \"ID swap applied due to invalid coordinate\"\n",
    "                    else:\n",
    "                        point_3d = np.array([np.nan, np.nan, np.nan])\n",
    "            elif np.any(np.abs(point_3d) > MAX_DISTANCE_FROM_ORIGIN):\n",
    "                reason = \"Coordinate out of physical bounds\"\n",
    "                point_3d = np.array([np.nan, np.nan, np.nan])\n",
    "            elif point_3d[2] < 0 or point_3d[2] > MAX_DEPTH:\n",
    "                reason = \"Negative or too large depth\"\n",
    "                point_3d = np.array([np.nan, np.nan, np.nan])\n",
    "\n",
    "            points_data.append({\n",
    "                \"frame\": frame,\n",
    "                \"id\": obj_id,\n",
    "                \"X\": point_3d[0],\n",
    "                \"Y\": point_3d[1],\n",
    "                \"Z\": point_3d[2],\n",
    "                \"swapped\": swapped,\n",
    "                \"reason\": reason\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(points_data)\n",
    "\n",
    "import os\n",
    "import re\n",
    "from difflib import get_close_matches\n",
    "\n",
    "def extract_base_cam10_11(fname):\n",
    "    base = os.path.basename(fname).lower()\n",
    "    # Extract string before _cam10_ or _cam11_\n",
    "    m = re.match(r'(.*)_cam1[01]_.*', base)\n",
    "    if m:\n",
    "        return m.group(1)\n",
    "    return None\n",
    "\n",
    "def extract_base_cam15_18(fname):\n",
    "    base = os.path.basename(fname).lower()\n",
    "    # Extract string before _cam15_ or _cam18_\n",
    "    m = re.match(r'(.*)_cam1[58]_.*', base)\n",
    "    if m:\n",
    "        return m.group(1)\n",
    "    return None\n",
    "\n",
    "def find_matched_sets(dir_cam10, dir_cam11, dir_cam15, dir_cam18):\n",
    "    files10 = os.listdir(dir_cam10)\n",
    "    files11 = os.listdir(dir_cam11)\n",
    "    files15 = os.listdir(dir_cam15)\n",
    "    files18 = os.listdir(dir_cam18)\n",
    "\n",
    "    bases_10 = {extract_base_cam10_11(f): f for f in files10 if extract_base_cam10_11(f)}\n",
    "    bases_11 = {extract_base_cam10_11(f): f for f in files11 if extract_base_cam10_11(f)}\n",
    "    bases_15 = {extract_base_cam15_18(f): f for f in files15 if extract_base_cam15_18(f)}\n",
    "    bases_18 = {extract_base_cam15_18(f): f for f in files18 if extract_base_cam15_18(f)}\n",
    "\n",
    "    matched = []\n",
    "\n",
    "    # Match cam10 & cam11 bases exactly\n",
    "    base_10_11 = set(bases_10.keys()) & set(bases_11.keys())\n",
    "\n",
    "    # For each base in cam10_11, find closest match in cam15 and cam18 bases using fuzzy matching\n",
    "    for base in base_10_11:\n",
    "        match_15 = get_close_matches(base, bases_15.keys(), n=1, cutoff=0.7)\n",
    "        match_18 = get_close_matches(base, bases_18.keys(), n=1, cutoff=0.7)\n",
    "\n",
    "        if match_15 and match_18:\n",
    "            matched.append((\n",
    "                os.path.join(dir_cam10, bases_10[base]),\n",
    "                os.path.join(dir_cam11, bases_11[base]),\n",
    "                os.path.join(dir_cam15, bases_15[match_15[0]]),\n",
    "                os.path.join(dir_cam18, bases_18[match_18[0]]),\n",
    "                base\n",
    "            ))\n",
    "\n",
    "    return matched\n",
    "\n",
    "def main():\n",
    "    base_dir = r\"D:\\DeepSORT_ML2025\\video_stitch\\sorted_csv\"\n",
    "    combinations = [\n",
    "        \"ind_pre\",\n",
    "        \"ind_post\",\n",
    "        \"rew_pre\",\n",
    "        \"rew_post\",\n",
    "        \"pro_pre\",\n",
    "        \"pro_post\"\n",
    "    ]\n",
    "\n",
    "    output_dir_root = r\"D:\\DeepSORT_ML2025\\video_stitch\\3d_transform\"\n",
    "\n",
    "    for comb in combinations:\n",
    "        print(f\"\\nProcessing condition: {comb}\")\n",
    "\n",
    "        dir_cam10 = os.path.join(base_dir, comb, \"cam10\", \"corrected_interpolated\")\n",
    "        dir_cam11 = os.path.join(base_dir, comb, \"cam11\", \"corrected_interpolated\")\n",
    "        dir_cam15 = os.path.join(base_dir, comb, \"cam15\", \"corrected_interpolated\")\n",
    "        dir_cam18 = os.path.join(base_dir, comb, \"cam18\", \"corrected_interpolated\")\n",
    "\n",
    "        output_dir = os.path.join(output_dir_root, comb)\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        matched_sets = find_matched_sets(dir_cam10, dir_cam11, dir_cam15, dir_cam18)\n",
    "        print(f\"Found {len(matched_sets)} matched sets for {comb}.\")\n",
    "\n",
    "        all_valid_dfs = []\n",
    "\n",
    "        for file10, file11, file15, file18, base_name in matched_sets:\n",
    "            print(f\"Processing set: {base_name}\")\n",
    "\n",
    "            df_cam10 = pd.read_csv(file10)\n",
    "            df_cam11 = pd.read_csv(file11)\n",
    "            df_cam15 = pd.read_csv(file15)\n",
    "            df_cam18 = pd.read_csv(file18)\n",
    "\n",
    "            df_cam10['camera'] = 10\n",
    "            df_cam11['camera'] = 11\n",
    "            df_cam15['camera'] = 15\n",
    "            df_cam18['camera'] = 18\n",
    "\n",
    "            tri_left = triangulate_with_reasons(df_cam10, df_cam18, K_cam10, K_cam18, R_10_18, T_10_18)\n",
    "            if tri_left.empty or 'X' not in tri_left.columns:\n",
    "                print(f\"Warning: triangulation left returned empty or no 'X' column for {base_name}\")\n",
    "                continue \n",
    "\n",
    "            tri_right = triangulate_with_reasons(df_cam11, df_cam15, K_cam11, K_cam15, R_11_15, T_11_15)\n",
    "            if tri_right.empty or 'X' not in tri_right.columns:\n",
    "                print(f\"Warning: triangulation right returned empty or no 'X' column for {base_name}\")\n",
    "                continue \n",
    "\n",
    "            # Now safe to do this\n",
    "            tri_right[\"X\"] += T_10_18[0][0]\n",
    "\n",
    "\n",
    "            tri_left.to_csv(os.path.join(output_dir, f\"triangulated_left_{base_name}.csv\"), index=False)\n",
    "            tri_right.to_csv(os.path.join(output_dir, f\"triangulated_right_{base_name}.csv\"), index=False)\n",
    "\n",
    "            all_points = pd.concat([tri_left, tri_right], axis=0)\n",
    "            pivoted = all_points.pivot_table(\n",
    "                index='frame', columns='id', values=['X', 'Y', 'Z', 'reason', 'swapped'], aggfunc='first')\n",
    "            pivoted.columns = ['{}_{}'.format(col[0], int(col[1])) for col in pivoted.columns]\n",
    "            pivoted = pivoted.reset_index()\n",
    "\n",
    "            frames = pivoted['frame'].values\n",
    "\n",
    "            distance_records = []\n",
    "            for _, row in pivoted.iterrows():\n",
    "                frame = row['frame']\n",
    "                valid_1 = all([pd.notna(row.get('X_1')), pd.notna(row.get('Y_1')), pd.notna(row.get('Z_1')),\n",
    "                               row.get('reason_1', '') in ['Valid', 'ID swap applied due to invalid coordinate']])\n",
    "                valid_2 = all([pd.notna(row.get('X_2')), pd.notna(row.get('Y_2')), pd.notna(row.get('Z_2')),\n",
    "                               row.get('reason_2', '') in ['Valid', 'ID swap applied due to invalid coordinate']])\n",
    "\n",
    "                if not valid_1 or not valid_2:\n",
    "                    reasons = []\n",
    "                    if not valid_1:\n",
    "                        reasons.append(f\"ID 1 invalid or missing ({row.get('reason_1', 'NA')})\")\n",
    "                    if not valid_2:\n",
    "                        reasons.append(f\"ID 2 invalid or missing ({row.get('reason_2', 'NA')})\")\n",
    "                    distance_records.append([frame, np.nan, \"; \".join(reasons)])\n",
    "                    continue\n",
    "\n",
    "                p1 = np.array([row['X_1'], row['Y_1'], row['Z_1']])\n",
    "                p2 = np.array([row['X_2'], row['Y_2'], row['Z_2']])\n",
    "                dist = np.linalg.norm(p1 - p2)\n",
    "                reason = \"Distance zero (suspicious)\" if dist == 0 else \"Valid\"\n",
    "                distance_records.append([frame, dist, reason])\n",
    "\n",
    "            dist_df = pd.DataFrame(distance_records, columns=['frame', 'distance_1_2', 'distance_reason'])\n",
    "            dist_df.to_csv(os.path.join(output_dir, f'interindividual_distances_with_reasons_{base_name}.csv'), index=False)\n",
    "\n",
    "            valid = dist_df[dist_df[\"distance_reason\"] == \"Valid\"][[\"frame\", \"distance_1_2\"]].copy()\n",
    "            valid[\"trial\"] = base_name\n",
    "            all_valid_dfs.append(valid)\n",
    "\n",
    "        # Plot summary for this condition\n",
    "        if all_valid_dfs:\n",
    "            combined = pd.concat(all_valid_dfs)\n",
    "\n",
    "            grouped = combined.groupby('frame')['distance_1_2']\n",
    "            frames_list = []\n",
    "            means = []\n",
    "            lowers = []\n",
    "            uppers = []\n",
    "\n",
    "            for frame, values in grouped:\n",
    "                vals = values.dropna().values\n",
    "                if len(vals) > 1:\n",
    "                    mean = np.mean(vals)\n",
    "                    sem = scipy.stats.sem(vals)\n",
    "                    ci_range = sem * scipy.stats.t.ppf((1 + 0.95) / 2., len(vals)-1)\n",
    "                    lower = mean - ci_range\n",
    "                    upper = mean + ci_range\n",
    "                elif len(vals) == 1:\n",
    "                    mean = vals[0]\n",
    "                    lower = mean\n",
    "                    upper = mean\n",
    "                else:\n",
    "                    mean = np.nan\n",
    "                    lower = np.nan\n",
    "                    upper = np.nan\n",
    "\n",
    "                frames_list.append(frame)\n",
    "                means.append(mean)\n",
    "                lowers.append(lower)\n",
    "                uppers.append(upper)\n",
    "\n",
    "            window = 15 if len(means) >= 15 else (len(means) // 2) * 2 + 1\n",
    "            smoothed_mean = savgol_filter(means, window_length=window, polyorder=2, mode='interp')\n",
    "            smoothed_lower = savgol_filter(lowers, window_length=window, polyorder=2, mode='interp')\n",
    "            smoothed_upper = savgol_filter(uppers, window_length=window, polyorder=2, mode='interp')\n",
    "\n",
    "            fig = go.Figure()\n",
    "\n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=frames_list + frames_list[::-1],\n",
    "                y=list(smoothed_upper) + list(smoothed_lower[::-1]),\n",
    "                fill='toself',\n",
    "                fillcolor='rgba(0,0,0,0.2)',\n",
    "                line=dict(color='rgba(255,255,255,0)'),\n",
    "                hoverinfo=\"skip\",\n",
    "                showlegend=True,\n",
    "                name=\"95% Confidence Interval\"\n",
    "            ))\n",
    "\n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=frames_list,\n",
    "                y=smoothed_mean,\n",
    "                mode='lines',\n",
    "                line=dict(color='black', width=3),\n",
    "                name='Smoothed Mean Distance',\n",
    "                hovertemplate=\"Frame %{x}<br>Distance %{y:.2f}<extra></extra>\"\n",
    "            ))\n",
    "\n",
    "            fig.update_layout(\n",
    "                title=f\"Inter-individual Distance Across Trials (Smoothed Mean ± 95% CI) - {comb}\",\n",
    "                xaxis_title=\"Frame\",\n",
    "                yaxis_title=\"Distance between ID 1 and ID 2\",\n",
    "                template=\"simple_white\",\n",
    "                height=500,\n",
    "                width=950,\n",
    "                showlegend=True,\n",
    "                yaxis=dict(range=[-500, 3000])  # fixed y-axis 0 to 1000\n",
    "            )\n",
    "\n",
    "            pio.show(fig)\n",
    "        else:\n",
    "            print(f\"No valid data to plot for {comb}.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
